<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LYTinn</title>
  
  <subtitle>My learning notes</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-09-06T02:26:40.683Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Run</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Neuron Layer Tutorial</title>
    <link href="http://example.com/2022/09/05/Neuron-Layer-Tutorial/"/>
    <id>http://example.com/2022/09/05/Neuron-Layer-Tutorial/</id>
    <published>2022-09-05T13:04:55.000Z</published>
    <updated>2022-09-06T02:26:40.683Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#example-1">Example 1</a></li><li><a href="#example-2">Example 2</a></li><li><a href="#example-3">Example 3</a></li><li><a href="#example-4">Example 4</a></li><li><a href="#tutorial-q1">Tutorial Q1</a><ul><li><a href="#a">a</a></li><li><a href="#b">b</a></li><li><a href="#c">c</a></li><li><a href="#d">d</a></li></ul></li><li><a href="#tutorial-q2">Tutorial Q2</a></li><li><a href="#tutorial-q3">Tutorial Q3</a></li></ul><p>Import corresponding packages first:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(<span class="string">&#x27;figures&#x27;</span>):</span><br><span class="line">    os.makedirs(<span class="string">&#x27;figures&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;3&#x27;</span></span><br></pre></td></tr></table></figure></p><h1 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h1><p>A perceptron layer of 3 neurons shown in the figure receives 2-dimensional inputs $(x_1, x_2)^T$, and has a weight matrix $\mathbf{W}$ and a bias vector $\mathbf{b}$ given by</p><script type="math/tex; mode=display">\mathbf{W} = \left(\begin{matrix}  0.133&0.072&-0.155\\-0.001&0.062&-0.072\end{matrix}\right)</script><script type="math/tex; mode=display">\mathbf{b} = \left(\begin{matrix}  0.017\\0.009\\0.069\end{matrix}\right)</script><p>Using batch processing, find the output for input patterns:</p><script type="math/tex; mode=display">\left(\begin{matrix}  0.5\\-1.66\end{matrix}\right),\left(\begin{matrix}  -1.0\\-0.51\end{matrix}\right),\left(\begin{matrix}  0.78\\-0.65\end{matrix}\right),\left(\begin{matrix}  0.04\\-0.2\end{matrix}\right)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># input data</span></span><br><span class="line">X = np.array([[<span class="number">0.5</span>,-<span class="number">1.66</span>],[-<span class="number">1.0</span>,-<span class="number">0.51</span>],[<span class="number">0.78</span>,-<span class="number">0.65</span>],[<span class="number">0.04</span>,-<span class="number">0.2</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(X))</span><br><span class="line"><span class="comment"># define weight and bias</span></span><br><span class="line">W = np.array([[<span class="number">0.133</span>, <span class="number">0.072</span>, -<span class="number">0.155</span>],</span><br><span class="line">             [-<span class="number">0.001</span>, <span class="number">0.062</span>, -<span class="number">0.072</span>]])</span><br><span class="line">b = np.array([<span class="number">0.017</span>, <span class="number">0.009</span>, <span class="number">0.069</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(W))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(b))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x:[[ 0.5  -1.66]</span><br><span class="line"> [-1.   -0.51]</span><br><span class="line"> [ 0.78 -0.65]</span><br><span class="line"> [ 0.04 -0.2 ]]</span><br><span class="line">W:[[ 0.133  0.072 -0.155]</span><br><span class="line"> [-0.001  0.062 -0.072]]</span><br><span class="line">b:[0.017 0.009 0.069]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define a class for a perceptron layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Layer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.w = tf.Variable(W, dtype=tf.float64)</span><br><span class="line">        self.b = tf.Variable(b, dtype=tf.float64)     </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, x</span>):</span><br><span class="line">        u = tf.matmul(x, self.w) + self.b</span><br><span class="line">        y = tf.sigmoid(u)</span><br><span class="line">        <span class="keyword">return</span> u, y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Layer()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, \nb: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w: [[ 0.133  0.072 -0.155]</span><br><span class="line"> [-0.001  0.062 -0.072]], </span><br><span class="line">b: [0.017 0.009 0.069]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">u, y = model(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;u: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(u))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(y))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">u: [[ 0.08516 -0.05792  0.11102]</span><br><span class="line"> [-0.11549 -0.09462  0.26072]</span><br><span class="line"> [ 0.12139  0.02486 -0.0051 ]</span><br><span class="line"> [ 0.02252 -0.00052  0.0772 ]]</span><br><span class="line">y: [[0.52127714 0.48552405 0.52772653]</span><br><span class="line"> [0.47115955 0.47636263 0.56481328]</span><br><span class="line"> [0.53031029 0.50621468 0.498725  ]</span><br><span class="line"> [0.50562976 0.49987    0.51929042]]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h1><h1 id="Example-3"><a href="#Example-3" class="headerlink" title="Example 3"></a>Example 3</h1><h1 id="Example-4"><a href="#Example-4" class="headerlink" title="Example 4"></a>Example 4</h1><h1 id="Tutorial-Q1"><a href="#Tutorial-Q1" class="headerlink" title="Tutorial Q1"></a>Tutorial Q1</h1><h2 id="a"><a href="#a" class="headerlink" title="a"></a>a</h2><h2 id="b"><a href="#b" class="headerlink" title="b"></a>b</h2><h2 id="c"><a href="#c" class="headerlink" title="c"></a>c</h2><h2 id="d"><a href="#d" class="headerlink" title="d"></a>d</h2><h1 id="Tutorial-Q2"><a href="#Tutorial-Q2" class="headerlink" title="Tutorial Q2"></a>Tutorial Q2</h1><h1 id="Tutorial-Q3"><a href="#Tutorial-Q3" class="headerlink" title="Tutorial Q3"></a>Tutorial Q3</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#example-1&quot;&gt;Example 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#example-2&quot;&gt;Example 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#example-3&quot;&gt;Example 3&lt;/a&gt;&lt;/li&gt;
&lt;li</summary>
      
    
    
    
    <category term="Deep Learning" scheme="http://example.com/categories/Deep-Learning/"/>
    
    
    <category term="tutorial" scheme="http://example.com/tags/tutorial/"/>
    
    <category term="Neuron Layer" scheme="http://example.com/tags/Neuron-Layer/"/>
    
  </entry>
  
  <entry>
    <title>Sentiment Analysis paper read</title>
    <link href="http://example.com/2022/09/05/Sentiment-Analysis-paper-read/"/>
    <id>http://example.com/2022/09/05/Sentiment-Analysis-paper-read/</id>
    <published>2022-09-05T06:03:13.000Z</published>
    <updated>2022-09-05T07:14:43.616Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#introduction">Introduction</a></li><li><a href="#smart">SMART</a><ul><li><a href="#dataset">Dataset</a></li><li><a href="#motivation">Motivation</a></li><li><a href="#result">Result</a></li></ul></li><li><a href="#unsupervised-data-augmentation-for-consistency-training">Unsupervised Data Augmentation for Consistency Training</a><ul><li><a href="#dataset-1">Dataset</a></li><li><a href="#motivation-1">Motivation</a></li><li><a href="#result-1">Result</a></li></ul></li></ul><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>In this post, we will read some top papers about sentiment analysis. The papers are choosen from <a href="https://paperswithcode.com/task/sentiment-analysis">paper with code</a>.</p><h1 id="SMART"><a href="#SMART" class="headerlink" title="SMART"></a>SMART</h1><p>The <a href="https://arxiv.org/pdf/1911.03437v5.pdf">SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization</a> published in 2019 is the state-of-the -art for sentiment analysis on SST-2 Binary classification. It achieves 97.5% in accuracy.</p><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>The dataset of this paper is the <strong>Standford Sentiment Treebank (SST)</strong>. SST is a corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language. The corpus is based on the dataset introduced by Pang and Lee (2005) and consists of 11,855 single sentences extracted from <strong>movie reviews</strong>. It was parsed with the Stanford parser and includes a total of 215,154 unique phrases from those parse trees, each annotated by 3 human judges.</p><p>Each phrase is labelled as either <em>negative, somewhat negative, neutral, somewhat positive</em> or <em>positive</em>. The corpus with all 5 labels is referred to as SST-5 or SST fine-grained. Binary classification experiments on full sentences (<em>negative</em> or <em>somewhat negative</em> vs <em>somewhat positive</em> or <em>positive</em> with <em>neutral</em> sentences discarded) refer to the dataset as SST-2 or SST binary.</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>When performing NLP models on downstream tasks, because of the limit fine-tuning data resources and high complexity of pre-trained model, the fine-tuning always cause overfitting.</p><p>The team comes up with a framework to fine-tune the pre-trained model on the downstream tasks, avoiding over-fitting and getting a better performance.</p><h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p>Achieves a new state-of-the-art performance on many NLP benchmarks like GLUE, SNLI, SciTail, ANLI.</p><h1 id="Unsupervised-Data-Augmentation-for-Consistency-Training"><a href="#Unsupervised-Data-Augmentation-for-Consistency-Training" class="headerlink" title="Unsupervised Data Augmentation for Consistency Training"></a>Unsupervised Data Augmentation for Consistency Training</h1><p>The <a href="https://arxiv.org/pdf/1904.12848v6.pdf">Unsupervised Data Augmentation for Consistency Training</a> published on 2019 is the state-of-the-art for sentiment analysis on Amazon Review Full. It achieves 65.83% accuracy on Amazon Review dataset.</p><h2 id="Dataset-1"><a href="#Dataset-1" class="headerlink" title="Dataset"></a>Dataset</h2><p>This dataset contains product reviews and metadata from Amazon, including 233.1 million reviews spanning May 1996 - Oct 2018.</p><p>This dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), links (also viewed/also bought graphs), and transaction metadata for each review shown on the review page.</p><h2 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h2><h2 id="Result-1"><a href="#Result-1" class="headerlink" title="Result"></a>Result</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smart&quot;&gt;SMART&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#dataset&quot;&gt;Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a hre</summary>
      
    
    
    
    <category term="Natural Language Processing" scheme="http://example.com/categories/Natural-Language-Processing/"/>
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="Sentiment Analysis" scheme="http://example.com/tags/Sentiment-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>Parts of Speech and Named Entities</title>
    <link href="http://example.com/2022/09/05/Parts-of-Speech-and-Named-Entities/"/>
    <id>http://example.com/2022/09/05/Parts-of-Speech-and-Named-Entities/</id>
    <published>2022-09-05T00:56:06.000Z</published>
    <updated>2022-09-05T08:41:28.083Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#pos-and-ner-sequence-labeling">POS and NER: Sequence Labeling</a><ul><li><a href="#parts-of-speech-pos">Parts of speech (POS)</a></li><li><a href="#named-entity-recognition-ner">Named Entity Recognition (NER)</a></li><li><a href="#sequence-labeling">Sequence labeling:</a></li></ul></li><li><a href="#pos-tagging">POS Tagging</a><ul><li><a href="#why-pos-tagging-is-challenging">Why POS tagging is challenging?</a></li><li><a href="#pos-tagging-with-hidden-markov-model-hmm">POS Tagging with Hidden Markov Model (HMM)</a><ul><li><a href="#pos-tagging-in-probabilistic-view">POS Tagging in probabilistic view:</a></li><li><a href="#markov-chains">Markov Chains</a></li><li><a href="#hidden-markov-model">Hidden Markov Model</a></li><li><a href="#pos-tagging-with-hmm">POS tagging with HMM</a></li></ul></li></ul></li><li><a href="#named-entity-recognition">Named Entity Recognition</a></li></ul><h1 id="POS-and-NER-Sequence-Labeling"><a href="#POS-and-NER-Sequence-Labeling" class="headerlink" title="POS and NER: Sequence Labeling"></a>POS and NER: Sequence Labeling</h1><h2 id="Parts-of-speech-POS"><a href="#Parts-of-speech-POS" class="headerlink" title="Parts of speech (POS)"></a>Parts of speech (POS)</h2><p>The parts of speech (POS) refers to <strong>word classes</strong> such as Noun, Verb, Adjective, etc. </p><p>It also known as lexical categories, word classes, morphological classes, lexical tags. Knowing word class tells us more about neighboring words and syntactic structure. E.g. nouns in English are often preceded by determiners and adjectives. Verbs have dependency links to nouns. POS tagging is a key aspect of parsing sentence structure.</p><h2 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition (NER)"></a>Named Entity Recognition (NER)</h2><p>The named entity recognition (NER) is proper name for person, location, organization, etc. </p><p>NEs are useful clues to sentence structure and meaning understanding. Knowing if a named entity like Washington is a name of person, a place, or a university is important to tasks like question answering and information extraction.</p><h2 id="Sequence-labeling"><a href="#Sequence-labeling" class="headerlink" title="Sequence labeling:"></a>Sequence labeling:</h2><ul><li><strong>POS tagging</strong> takes a sequence of words and assigns each word a POS like NOUN or VERB.</li><li><strong>Named Entity Recognition (NER)</strong> assigns words or phrases tags like PERSON, LOCATION, or ORGANIZATION.</li></ul><h1 id="POS-Tagging"><a href="#POS-Tagging" class="headerlink" title="POS Tagging"></a>POS Tagging</h1><p>There are multiple POS tagsets defined. For example, the following are 17 parts of speech in the Universal Dependecies tagset.<br><img src="../figures/POStagging.png" alt="pos tagging"></p><p><strong>Closed classes</strong> are those with relatively <strong>fixed membership</strong>, such as prepositions; new prepositions are rarely coined.</p><p>Closed class words are generally <strong>function words</strong> (e.g. of, it, and) which tend to be very short, occur frequently, and often have structuring uses in grammar.</p><p>Nouns and verbs are maong <strong>open classes</strong>; new nouns and verbs like <em>iPhone</em> or <em>fax</em> are continually being created or borrowed.</p><p><strong>Prepositions</strong> indicate spatial ot temporal relations, and relations.</p><p><strong>Determiners</strong> like <em>this</em> and <em>that</em> can mark the start of article English noun phrase.</p><p><strong>Pronouns</strong> acts as a shorthand for referring to an entity or event.</p><ul><li><strong>Persional pronouns</strong> refer to person or entities (you, she, I, it, me, etc.)</li><li><strong>Possessive pronouns</strong> are forms of personal pronouns that indicate either actual possession ot more often just an abstract relation between the person and some object (my, your, his, her, its, one’s, our, their, etc.)</li><li><strong>Wh-pronouns</strong> (What, who, whom, whoever, etc.) are used in certain question forms, or act as complementizers.</li></ul><p>The 45-tag Penn Treebanc tagset is another tagset example.<br><img src="../figures/45-tag.png" alt="45-tag"></p><p>Part-of-speech tagging is the process of assigning a part-of-speech to each word in a text.</p><h2 id="Why-POS-tagging-is-challenging"><a href="#Why-POS-tagging-is-challenging" class="headerlink" title="Why POS tagging is challenging?"></a>Why POS tagging is challenging?</h2><p>Words are <strong>ambiguous</strong> — have more than one possible part-of-speech. And the example words may contain multiple parts-of-speech. For example:</p><blockquote><p><strong>Book</strong> that flight; Hand me that <strong>book</strong>.</p><p>The <strong>back</strong> door; On my <strong>back</strong>; Win the voters <strong>back</strong>; Promised to <strong>back</strong> the bill.</p></blockquote><p>How to determine the tag of word is a hard problem, there are many algorithms discusing and trying to solve it. The accuracy of POS tagging algorithms is extremely high, about 97%. However, the most-frequent-tag baseline has an accuracy of about 92%.</p><p>Here, we won’t discuss tagging algorithm in detail. We will focus on predicting and generating sentence using tags.</p><h2 id="POS-Tagging-with-Hidden-Markov-Model-HMM"><a href="#POS-Tagging-with-Hidden-Markov-Model-HMM" class="headerlink" title="POS Tagging with Hidden Markov Model (HMM)"></a>POS Tagging with Hidden Markov Model (HMM)</h2><p>A sequence labeler assigns a label to each unit (e.g. word) in a sequence (i.e. sentence), thus mapping a sequence of observations to a sequence of labels of the same length.</p><p>The HMM is a classic probabilitic sequence model. Given a sequence of words, it computes a probability distribution over possible sequences of labels and chooses that best label sequence.</p><h3 id="POS-Tagging-in-probabilistic-view"><a href="#POS-Tagging-in-probabilistic-view" class="headerlink" title="POS Tagging in probabilistic view:"></a>POS Tagging in probabilistic view:</h3><ul><li>Consider all possible sequences of tag (each tag for one word)</li><li>Out of this universe of sequences, choose the tag sequence which is most probable given the observation sequence of $n$ words $w_1\dots w_n$.</li></ul><h3 id="Markov-Chains"><a href="#Markov-Chains" class="headerlink" title="Markov Chains"></a>Markov Chains</h3><p>The HMM is based on augmenting the <strong>Markov chain</strong>. A Markov chain is a model on the probabilities of sequences of random variables (or states), each of which can take on values from some set. These sets can be tags, words, or symbols representing anything. For example, a set of possible weather states includes HOT, COLD, WARM.</p><p>Markov assumption: The probability of next state only depends on the current state, e.g. predict tomorrow’s weather only based on todays’ weather.</p><script type="math/tex; mode=display">P(q_i = a | q_1\dots q_{i-1}) = P(q_i = a|q_{i-1})</script><p>where $q<em>1\dots q</em>{i-1}$ is a sequence of states. The probability of next state $q<em>i=a$ only depends on the state $q</em>{i-1}$.</p><script type="math/tex; mode=display">Q = q_1q_2\dots q_N\qquad</script><p>$Q$ is a set of N <strong>states</strong>.</p><script type="math/tex; mode=display">A = \left(\begin{matrix}    a_{11}&\dots&a_{1N}\\    \vdots&\ddots\\    a_{N1}&\dots&a_{NN}\end{matrix}\right)\qquad</script><p>$A$ is <strong>transition probability matrix</strong> A, each $a<em>{ij}$ representing the probability of moving from state $i$ to state $j$, s.t. $\sum</em>{j=1}^na_{ij} = 1\quad \forall i$</p><script type="math/tex; mode=display">\pi = \pi_1, \pi_2, \dots, \pi_N</script><p>$\pi$ is the initial probability distribution over states. $\pi<em>i$ is the probability that the Markov chain will start in state $i$. Some states $j$ may have $\pi_i = 0$, meaning that they cannot be initial states. Also, $\sum</em>{i=1}^n\pi_i = 1$.</p><h3 id="Hidden-Markov-Model"><a href="#Hidden-Markov-Model" class="headerlink" title="Hidden Markov Model"></a>Hidden Markov Model</h3><p>A Markov chain is useful when we need to compute a probability for a sequence of observable events, e.g., based on today’s weather to predict tomorrow’s weather, and based on current word to predict next word (as in bigram model).</p><p>In many cases, however, the events we are interested in are <strong>hidden</strong>. For example, in POS tagging, we can only observe words, but not there tags. We cannot use the current tag to predict the next tag for a word sequence. We call the tags hidden because they are not observed.</p><p>A hidden Markov model (HMM) allows us to talk about both <strong>observed events</strong> and <strong>hidden events</strong>. For POS tagging:</p><ul><li>Observed event are the words in the input sentence. </li><li>Hidden events are the part-of-speech tags for these words.</li><li>The observed events are considered as causal factors in this probabilistic model.</li></ul><script type="math/tex; mode=display">Q = q_1q_2\dots q_N\qquad</script><p>$Q$ is a set of N <strong>states</strong>.</p><script type="math/tex; mode=display">A = \left(\begin{matrix}    a_{11}&\dots&a_{1N}\\    \vdots&\ddots\\    a_{N1}&\dots&a_{NN}\end{matrix}\right)\qquad</script><p>$A$ is <strong>transition probability matrix</strong> A, each $a<em>{ij}$ representing the probability of moving from state $i$ to state $j$, s.t. $\sum</em>{j=1}^na_{ij} = 1\quad \forall i$</p><script type="math/tex; mode=display">O = o_1o_2\dots o_T</script><p>$O$ is a sequence of $T$ <strong>observations</strong>, each one drawn from a vocabulary $V = v_1v_2\dots v_V$</p><script type="math/tex; mode=display">B = b_i(o_t)</script><p>$B$ is a sequence of <strong>observation likelihoods</strong>, also called <strong>emission probabilities</strong>, each expressing the probability of an observation $o_t$ being generated from a state $q_i$.</p><script type="math/tex; mode=display">\pi = \pi_1, \pi_2, \dots, \pi_N</script><p>$\pi$ is the initial probability distribution over states. $\pi<em>i$ is the probability that the Markov chain will start in state $i$. Some states $j$ may have $\pi_i = 0$, meaning that they cannot be initial states. Also, $\sum</em>{i=1}^n\pi_i = 1$.</p><p>A first-order hidden Markov model instantiates two simplifying assumptions:</p><p><strong>Markov Assumption</strong>: the probability of a particular state depends only on the previous state</p><script type="math/tex; mode=display">P(q_i=a|q_1q_2\dots q_{i-1}) = P(q_i=a|q_{i-1})</script><p><strong>Output Independence Assumption</strong>: the probability of an output observation $o_i$ depends only on the state $q_i$ that produced the observation and not on any other states or any otehr observations</p><script type="math/tex; mode=display">P(o_i|q_1,\dots, q_T; o_1,\dots, o_T) = P(o_i|q_i)</script><p><strong>Decoding</strong>: For any model, such as an HMM, that contains hidden variables, the task of determining the hidden variables sequence corresponding to the sequence of observations is called decoding.</p><h3 id="POS-tagging-with-HMM"><a href="#POS-tagging-with-HMM" class="headerlink" title="POS tagging with HMM"></a>POS tagging with HMM</h3><p>Out of all possible sequences of $n$ tags $t_1\dots t_n$ the single tag sequence such that $P(t_1\dots t_n|w_1\dots w_n)$  is highest.</p><script type="math/tex; mode=display">\hat{t}_{1:n} = \arg \max_{t_{1:n}}P(t_{1:n}|w_{1:n})</script><p>where the $\hat{t}$ means <strong>our estimate</strong> of the best one.</p><p>Use Bayes rule $P(y|x) = \frac{P(x|y)P(y)}{P(x)}$ to transform this equation into a set of other probabilities that are easier to compute:</p><script type="math/tex; mode=display">\hat{t}_{1:n} = \arg \max_{t_{1:n}}P(t_{1:n}|w_{1:n}) = \arg \max_{t_{1:n}}\frac{P(w_{1:n}|t_{1:n})P(t_{1:n})}{P(w_{1:n})} = \arg\max_{t_{1:n}}P(w_{1:n}|t_{1:n})P(t_{1:n})</script><p>Applying the two assumptions of HMM, we can get:</p><script type="math/tex; mode=display">\hat{t}_{1:n} = \arg\max_{t_{1:n}}\prod_{i=1}^nP(w_i|t_i)P(t_i|t_{i-1})</script><h1 id="Named-Entity-Recognition"><a href="#Named-Entity-Recognition" class="headerlink" title="Named Entity Recognition"></a>Named Entity Recognition</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#pos-and-ner-sequence-labeling&quot;&gt;POS and NER: Sequence Labeling&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#parts-of-speech-pos&quot;&gt;Parts of speech </summary>
      
    
    
    
    <category term="Natural Language Processing" scheme="http://example.com/categories/Natural-Language-Processing/"/>
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Basic MLP</title>
    <link href="http://example.com/2022/09/04/Neuron-Layer/"/>
    <id>http://example.com/2022/09/04/Neuron-Layer/</id>
    <published>2022-09-04T01:00:58.000Z</published>
    <updated>2022-09-05T12:59:16.097Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#neuron-layer">Neuron Layer</a><ul><li><a href="#weight-matrix-of-a-layer">Weight matrix of a layer</a></li><li><a href="#synaptic-input-at-a-layer-for-single-input">Synaptic input at a layer for single input</a></li><li><a href="#synaptic-input-to-a-layer-for-batch-input">Synaptic input to a layer for batch input</a></li><li><a href="#activation-at-a-layer-for-batch-input">Activation at a layer for batch input</a></li><li><a href="#sgd-for-single-layer">SGD for single layer</a></li><li><a href="#gd-for-single-layer">GD for single layer</a></li><li><a href="#conclusion-for-neuron-layer">Conclusion for Neuron Layer</a></li></ul></li><li><a href="#perceptron-layer">Perceptron Layer</a><ul><li><a href="#sgd-for-perceptron-layer">SGD for perceptron layer</a></li><li><a href="#gd-for-perceptron-layer">GD for perceptron layer</a></li><li><a href="#conclusion-for-perceptron-layer">Conclusion for Perceptron Layer</a></li></ul></li><li><a href="#softmax-layer">Softmax Layer</a><ul><li><a href="#sgd-for-softmax-layer">SGD for softmax layer</a></li><li><a href="#gd-for-softmax-layer">GD for softmax layer</a></li><li><a href="#conclusion-for-softmax-layer">Conclusion for softmax layer</a></li></ul></li><li><a href="#initialization-of-weights">Initialization of weights</a><ul><li><a href="#initialization-from-a-uniform-distribution">Initialization from a uniform distribution</a></li><li><a href="#initialization-from-a-truncated-normal-distribution">Initialization from a truncated normal distribution</a></li></ul></li></ul><h1 id="Neuron-Layer"><a href="#Neuron-Layer" class="headerlink" title="Neuron Layer"></a>Neuron Layer</h1><p>A Layer of perceptrons performs <strong>multidimensional linear regression</strong> and learns a multidimensional linear mapping:</p><script type="math/tex; mode=display">\phi: \mathbb{R}^n \rightarrow\mathbb{R}^K</script><h2 id="Weight-matrix-of-a-layer"><a href="#Weight-matrix-of-a-layer" class="headerlink" title="Weight matrix of a layer"></a>Weight matrix of a layer</h2><p>Consider a layer of K neurons:<br><img src="../figures/K%20neurons.png" alt="K neurons"></p><p>Let $\mathbf{W_k}$ and $b_k$ denote the weight vector and bias of $k$ th neuron. Weights connected to a neuron layer is represented by a weight matrix $\mathbf{W}$ where the columns are given by weight vectors of individual neurons:</p><script type="math/tex; mode=display">\mathbf{W} = (\mathbf{w_1}\quad\mathbf{w_2}\quad\dots\quad\mathbf{w_k})</script><p>and a bias vector $\mathbf{b}$ where each element corresponds to a bias of a neuron:</p><script type="math/tex; mode=display">\mathbf{b} = (b_1, b_2, \dots, b_K)^T</script><h2 id="Synaptic-input-at-a-layer-for-single-input"><a href="#Synaptic-input-at-a-layer-for-single-input" class="headerlink" title="Synaptic input at a layer for single input"></a>Synaptic input at a layer for single input</h2><p>Given an input pattern $x\in \mathbb{R}^n$ to a layer of $K$ neurons. The synaptic input $u_k$ to $k$ th neuron is:</p><script type="math/tex; mode=display">u_k = \mathbf{w}_k^T\mathbf{x}+ b_k</script><p>where $\mathbf{w}_k$ and $b_k$ denote the weight vector and bias of $k$th neuron. Synaptic input vector $u$ to the layer is:</p><script type="math/tex; mode=display">\mathbf{u} = \left(\begin{array}{cc}    u_1\\u_2\\\vdots\\u_k\end{array}\right) = \left(\begin{array}{cc}    \mathbf{w}_1^T\mathbf{x} + b_1\\    \mathbf{w}_2^T\mathbf{x} + b_2\\    \vdots\\    \mathbf{w}_k^T\mathbf{x} + b_k\end{array}\right) = \left(\begin{array}{cc}    \mathbf{w}_1^T\\    \mathbf{w}_2^T\\    \vdots\\    \mathbf{w}_k^T\\\end{array}\right)\mathbf{x} + \left(\begin{array}{cc}    b_1\\b_2\\\vdots\\b_k\end{array}\right) = \mathbf{W}^T\mathbf{x} + \mathbf{b}</script><p>where $\mathbf{W}$ is the weight matrix and $\mathbf{b}$ is the bias vector of the layer.</p><h2 id="Synaptic-input-to-a-layer-for-batch-input"><a href="#Synaptic-input-to-a-layer-for-batch-input" class="headerlink" title="Synaptic input to a layer for batch input"></a>Synaptic input to a layer for batch input</h2><p>Given a set ${\mathbf{x}<em>p }</em>{p=1}^P$ input patterns to a layer of $K$ neurons where $\mathbf{x}_p\in \mathbb{R}^n$.</p><p>Synaptic input $\mathbf{u}_p$ to the layer for an input pattern $\mathbf{x}_p$ is:</p><script type="math/tex; mode=display">\mathbf{u}_p = \mathbf{W}^T\mathbf{x}_p + \mathbf{b}</script><p>The synaptic input matrix $\mathbf{U}$ to the layer for P patterns:</p><script type="math/tex; mode=display">\mathbf{U} = \left(\begin{array}{cc}    \mathbf{x}_1^T\mathbf{W} + \mathbf{b}^T\\    \mathbf{x}_2^T\mathbf{W} + \mathbf{b}^T\\    \vdots\\    \mathbf{x}_P^T\mathbf{W} + \mathbf{b}^T\end{array}\right) = \left(\begin{array}{cc}    \mathbf{x}_1^T\\    \mathbf{x}_2^T\\    \vdots\\    \mathbf{x}_P^T\end{array}\right)\mathbf{W} + \left(\begin{array}{cc}    \mathbf{b}^T\\\mathbf{b}^T\\\vdots\\\mathbf{b}^T\end{array}\right) = \mathbf{XW} + \mathbf{B}</script><p>where rows $\mathbf{U}$ are synaptic inputs corresponding to individual input patterns.</p><p>The matrix </p><script type="math/tex; mode=display">\mathbf{B} = \left(\begin{array}{cc}    \mathbf{b}^T\\\mathbf{b}^T\\\vdots\\\mathbf{b}^T\end{array}\right)</script><p>has bias vector propagated as rows.</p><p>Using batch in deep learning could accerate the speed of training.</p><h2 id="Activation-at-a-layer-for-batch-input"><a href="#Activation-at-a-layer-for-batch-input" class="headerlink" title="Activation at a layer for batch input"></a>Activation at a layer for batch input</h2><p>Activation of the layer of synaptic input to the layer due to a batch of patterns:</p><script type="math/tex; mode=display">f(\mathbf{U}) = \left(\begin{array}{cc}    f(\mathbf{u}_1^T) \\ f(\mathbf{u}_2^T) \\\vdots \\f(\mathbf{u}_P^T)\end{array}\right) = \left(\begin{array}{cc}    f(\mathbf{u}_1)^T\\    f(\mathbf{u}_2)^T\\    \vdots\\    f(\mathbf{u}_P)^T\end{array}\right)</script><p>where activation of each pattern is written as rows.</p><h2 id="SGD-for-single-layer"><a href="#SGD-for-single-layer" class="headerlink" title="SGD for single layer"></a>SGD for single layer</h2><p>Computational graph for processing input $(\mathbf{x}, \mathbf{d})$:<br><img src="../figures/SGD-for-single-layer.png" alt="SGD for single layer"></p><p>$J$ denotes the cost function. Now, we need to compute gradients $\nabla<em>\mathbf{W}J$ and $\nabla</em>\mathbf{b}J$ to learn the weight matrix $\mathbf{W}$ and the bias vector $\mathbf{b}$.</p><p>Consider $k$th neuron at the layer:</p><script type="math/tex; mode=display">u_k = \mathbf{w}_k^T\mathbf{x} + b_k = \sum_{i=0}^nw_{ki}x_i + b_k</script><p>where n is the rank of $\mathbf{x}$. So that</p><script type="math/tex; mode=display">\begin{aligned}    &\frac{\partial u_k}{\partial\mathbf{W}_k}\\    =& \left(\begin{array}{cc}        \frac{\partial (\sum_{i=0}^nw_{ki}x_i + b_k)}{\partial w_{k1}}\\        \frac{\partial (\sum_{i=0}^nw_{ki}x_i + b_k)}{\partial w_{k2}}\\        \vdots\\        \frac{\partial (\sum_{i=0}^nw_{ki}x_i + b_k)}{\partial w_{kn}}    \end{array}\right)\\    =&\left(\begin{array}{cc}        x_1\\x_2\\\vdots\\x_d    \end{array}\right)\\    =&\mathbf{x}\end{aligned}</script><p>The gradient of the cost with respect to the weight connected to $k$th neuron is:</p><script type="math/tex; mode=display">\nabla_{\mathbf{w}_k}J = \frac{\partial J}{\partial u_k}\frac{\partial u_k}{\partial \mathbf{w}_k} = \mathbf{x}\frac{\partial J}{\partial u_k}</script><script type="math/tex; mode=display">\nabla_{b_k}J = \frac{\partial J}{\partial u_k}\frac{\partial u_k}{\partial b_k} = \frac{\partial J}{\partial u_k}</script><p>The gradient of $J$ with respect to $\mathbf{W} = (\mathbf{w_1}\quad \mathbf{w_2}\quad\dots\quad\mathbf{w}_k)$:</p><script type="math/tex; mode=display">\begin{aligned}    \nabla_wJ &= (\nabla_{\mathbf{w}1}J\quad\nabla_{\mathbf{w}2}J\quad\dots\quad\nabla_{\mathbf{w}K}J)\\    &=\left(\mathbf{x}\frac{\partial J}{\partial u_1}\quad\mathbf{x}\frac{\partial J}{\partial u_2}\quad\dots\quad\mathbf{x}\frac{\partial J}{\partial u_K}\right)\\    &=\mathbf{x}\left(\frac{\partial J}{\partial u_1}\quad\frac{\partial J}{\partial u_2}\quad\dots\quad\frac{\partial J}{\partial u_K}\right)\\    &=\mathbf{x}(\nabla_\mathbf{u}J)^T\end{aligned}</script><p>where</p><script type="math/tex; mode=display">\nabla_\mathbf{u}J = \frac{\partial J}{\partial \mathbf{u}} = \left(\begin{array}{cc}    \frac{\partial J}{\partial u_1}\\\frac{\partial J}{\partial u_2}\\\vdots\\\frac{\partial J}{\partial u_K}\end{array}\right)</script><p>Similarly, by substituting $\frac{\partial J}{\partial b_k} = \frac{\partial J}{\partial u_k}$:</p><script type="math/tex; mode=display">\nabla_\mathbf{b}J = \left(\begin{array}{cc}        \frac{\partial J}{\partial b_1}\\        \frac{\partial J}{\partial b_2}\\\vdots\\        \frac{\partial J}{\partial b_K}    \end{array}\right) = \left(\begin{array}{cc}        \frac{\partial J}{\partial u_1}\\        \frac{\partial J}{\partial u_2}\\\vdots\\        \frac{\partial J}{\partial u_K}    \end{array}\right) = \nabla_\mathbf{u}J</script><p>Thus, for any income data $\mathbf{x}$, the gradients of $\mathbf{w}$ and $b$ are:</p><script type="math/tex; mode=display">\nabla_\mathbf{w}J = \mathbf{x}(\nabla_\mathbf{u}J)^T\\\nabla_\mathbf{b}J = \nabla_\mathbf{u}J</script><p>That is, by computing gradient $\nabla_\mathbf{u}J$ with respect to synaptic input $\mathbf{u}$, the gradient of cost $J$ with respect to the weights and biases is obtained.</p><h2 id="GD-for-single-layer"><a href="#GD-for-single-layer" class="headerlink" title="GD for single layer"></a>GD for single layer</h2><p>Given a set of patterns ${(\mathbf{x}<em>p, \mathbf{d}_p)}</em>{p=1}^P$ where $\mathbf{x}_p\in \mathbb{R}^n$ and $\mathbf{d}_p\in \mathbb{R}^K$ for regression and $d_p\in {1, 2, \dots, K}$ for classification.</p><p>The cost $J$ is given by the sum of cost due to individual patterns:</p><script type="math/tex; mode=display">J = \sum_{p=1}^PJ_p</script><p>where then:</p><script type="math/tex; mode=display">\nabla_\mathbf{W}J = \sum_{p=1}^P\nabla_\mathbf{w}J_p</script><p>Substituting $\nabla<em>\mathbf{W}J_p = \mathbf{x}_p(\nabla</em>{\mathbf{u}_p}J_p)^T$:</p><script type="math/tex; mode=display">\begin{aligned}    \nabla_\mathbf{W}J &= \sum_{p=1}^P\mathbf{x}_p(\nabla_{\mathbf{u}_p}J_p)^T\\    &=\sum_{p=1}^P\mathbf{x}_p(\nabla_{\mathbf{u}_p}J)^T\qquad\text{since }\nabla_{\mathbf{u}_p}J = \nabla_{\mathbf{u}_p}J_p\\    &=\mathbf{x}_1(\nabla_{\mathbf{u}_1}J)^T + \mathbf{x}_2(\nabla_{\mathbf{u}_2}J)^T + \dots + \mathbf{x}_P(\nabla_{\mathbf{u}_P}J)^T\\    &= (\mathbf{x}_1\quad\mathbf{x}_2\quad\dots\quad\mathbf{x}_P)\left(\begin{array}{cc}        (\nabla_{\mathbf{u}_1}J)^T\\        (\nabla_{\mathbf{u}_2}J)^T\\        \vdots\\        (\nabla_{\mathbf{u}_P}J)^T    \end{array}\right)\\    &= \mathbf{X}^T\nabla_\mathbf{U}J\end{aligned}</script><p>Note that $\mathbf{X} = \left(\begin{array}{cc}<br>    \mathbf{x}<em>1^T\\mathbf{x}_2^T\\vdots\\mathbf{x}_P^T<br>\end{array}\right)$ and $\mathbf{U} = \left(\begin{array}{cc}<br>    \mathbf{u}_1^T\\mathbf{u}_2^T\\vdots\\mathbf{u}_P^T<br>\end{array}\right)$<br>For the biases, substitute with $\nabla</em>{\mathbf{u}<em>p}J = \nabla</em>{\mathbf{u}_p}J_p$</p><script type="math/tex; mode=display">\begin{aligned}    \nabla_\mathbf{b}J &= \sum_{p=1}^P\nabla_\mathbf{b}J_p\\    &=\sum_{p=1}^P\nabla_{\mathbf{u}_p}J_p\\    &=\sum_{p=1}^P\nabla_{\mathbf{u}_p}J\\    &=\nabla_{\mathbf{u}_1}J + \nabla_{\mathbf{u}_2}J + \dots + \nabla_{\mathbf{u}_P}J\\    &= (\nabla_{\mathbf{u}_1}J\quad\nabla_{\mathbf{u}_2}J\quad\dots\quad\nabla_{\mathbf{u}_P}J)\left(\begin{array}{cc}        1\\1\\\vdots\\1    \end{array}\right)\\    &= (\nabla_\mathbf{U})^T\mathbf{1}_P\end{aligned}</script><p>where $\mathbf{1}_P = (1, 1, \dots, 1)^T$ is a vector of $P$ ones.</p><p>That is, by computing gradient $\nabla_\mathbf{U}J$ with respect to synaptic input, the weights and biases can be updated.</p><h2 id="Conclusion-for-Neuron-Layer"><a href="#Conclusion-for-Neuron-Layer" class="headerlink" title="Conclusion for Neuron Layer"></a>Conclusion for Neuron Layer</h2><p><img src="../figures/linear_learning.png" alt="neuron layer"></p><h1 id="Perceptron-Layer"><a href="#Perceptron-Layer" class="headerlink" title="Perceptron Layer"></a>Perceptron Layer</h1><p>A layer of perceptrons performs <strong>multidimensional non-linear regression</strong> and learns a multidimensional non-linear mapping:</p><script type="math/tex; mode=display">\phi = \mathbb{R}^n \rightarrow \mathbb{R}^K</script><h2 id="SGD-for-perceptron-layer"><a href="#SGD-for-perceptron-layer" class="headerlink" title="SGD for perceptron layer"></a>SGD for perceptron layer</h2><p>Given a training pattern $(\mathbf{x}, \mathbf{d})$, note $\mathbf{x} = (x_1, x_2, \dots, x_n)^T \in \mathbb{R}^n$ and $\mathbf{d} = (d_1, d_2, \dots, d_K)^T\in \mathbb{R}^K$. The square error cost function is:</p><script type="math/tex; mode=display">J = \frac{1}{2}\sum_{k=1}^K(d_k - y_k)^2</script><p>where $y_k = f(u_k) = \frac{1}{1+e^{-u_k}}$ and $u_k = \mathbf{x}^T\mathbf{w}_k + b_k$. $\mathbf{u_k}$ is the synaptic input of the $k$th neuron. $J$ is the sum of square errors of all the nueron outputs. Gradient of $J$ with respect to $u_k$ is:</p><script type="math/tex; mode=display">\frac{\partial J}{\partial u_k} = \frac{\partial J}{\partial y_k}\frac{\partial y_k}{\partial u_k} = -(d_k - y_k)\frac{\partial y_k}{\partial u_k} = -(d_k - y_k)f'(u_k)</script><p>Substituting $\nabla_{u_k}J = \frac{\partial J}{\partial u_k} = -(d_k - y_k)f’(u_k)$:</p><script type="math/tex; mode=display">\nabla_\mathbf{u}J = -\left(\begin{array}{cc}    (d_1 - y_1)f'(u_1)\\(d_2 - y_2)f'(u_2)\\\vdots\\(d_1 - y_1)f'(u_1)\end{array}\right) = -(\mathbf{d} - \mathbf{y})\cdot f'(\mathbf{u})</script><p>where “$\cdot$” means element-wise multiplication.</p><p>The algorithm is:</p><script type="math/tex; mode=display">\begin{aligned}    &\text{Given a training dataset} \{(\mathbf{x}, \mathbf{d})\}\\    &\text{Set learning parameter }\alpha\\    &\text{Initialize $\mathbf{W}$ and $\mathbf{b}$}\\    &\text{Repeat until convergence:}\\    &\qquad\text{For every pattern }(\mathbf{x}, \mathbf{d}):\\    &\qquad\qquad \mathbf{u} = \mathbf{W}^T\mathbf{x} + \mathbf{b}\\    &\qquad\qquad \mathbf{y} = f(\mathbf{u}) = \frac{1}{1+e^{-\mathbf{u}}}\\    &\qquad\qquad\nabla_\mathbf{u}J = -(\mathbf{d} - \mathbf{y})\cdot f'(\mathbf{u})\\    &\qquad\qquad\nabla_\mathbf{W}J = \mathbf{x}(\nabla_\mathbf{u}J)^T\\    &\qquad\qquad\nabla_\mathbf{b}J = \nabla_\mathbf{u}J\\    &\qquad\qquad\mathbf{W}\leftarrow\mathbf{W} - \alpha\nabla_\mathbf{W}J\\    &\qquad\qquad\mathbf{b}\leftarrow\mathbf{b} - \alpha\nabla_\mathbf{b}J\end{aligned}</script><h2 id="GD-for-perceptron-layer"><a href="#GD-for-perceptron-layer" class="headerlink" title="GD for perceptron layer"></a>GD for perceptron layer</h2><p>Given a training dataset ${\mathbf{x}<em>p, \mathbf{d}_p}</em>{p=1}^P$. Note $\mathbf{x}<em>p = (x</em>{p1}, x<em>{p2}, \dots, x</em>{pn})^T \in \mathbb{R}^n$ and $\mathbf{d}<em>p = (d</em>{p1}, d<em>{p2}, \dots, d</em>{pK})^T\in \mathbb{R}^K$.</p><p>The cost function $J$ is given by the sum of square errors:</p><script type="math/tex; mode=display">J = \frac{1}{2}\sum_{p=1}^P\sum_{k=1}^K(d_{pk} - y_{pk})^2</script><p>$J$ can be written as the sum of cost due to individual patterns:</p><script type="math/tex; mode=display">J = \sum_{p=1}^PJ_p</script><p>where $J<em>p = \frac{1}{2}\sum</em>{k=1}^K(d<em>{pk} - y</em>{pk})^2$ is the square error for the $p$th pattern.</p><script type="math/tex; mode=display">U = \left(\begin{array}{cc}    \mathbf{u}_1^T\\\mathbf{u}_2^T\\\vdots\\\mathbf{u}_P^T\end{array}\right)\rightarrow\nabla_\mathbf{u}J = \left(\begin{array}{cc}    (\nabla_{\mathbf{u}_1}J)^T\\(\nabla_{\mathbf{u}_2}J)^T\\\vdots\\(\nabla_{\mathbf{u}_P}J)^T\end{array}\right) = \left(\begin{array}{cc}    (\nabla_{\mathbf{u}_1}J_1)^T\\(\nabla_{\mathbf{u}_2}J_2)^T\\\vdots\\(\nabla_{\mathbf{u}_P}J_P)^T\end{array}\right)</script><p>substitute $\nabla_\mathbf{u}J = -(\mathbf{b} - \mathbf{y})\cdot f’(\mathbf{u})$:</p><script type="math/tex; mode=display">\nabla_\mathbf{u}J = -\left(\begin{array}{cc}    ((\mathbf{d}_1 - \mathbf{y}_1)\cdot f'(\mathbf{u}_1))^T\\    ((\mathbf{d}_2 - \mathbf{y}_2)\cdot f'(\mathbf{u}_2))^T\\    \vdots\\    ((\mathbf{d}_P - \mathbf{y}_P)\cdot f'(\mathbf{u}_P))^T\end{array}\right) = -\left(\begin{array}{cc}    (\mathbf{d}_1^T - \mathbf{y}_1^T)\cdot f'(\mathbf{u}_1^T)\\    (\mathbf{d}_2^T - \mathbf{y}_2^T)\cdot f'(\mathbf{u}_2^T)\\    \vdots\\    (\mathbf{d}_P^T - \mathbf{y}_P^T)\cdot f'(\mathbf{u}_P^T)\end{array}\right)</script><script type="math/tex; mode=display">\nabla_\mathbf{U}J = -(\mathbf{D} - \mathbf{Y})\cdot f'(\mathbf{U})</script><p>where $\mathbf{D} = \left(\begin{array}{cc}<br>    \mathbf{d}_1^T\\mathbf{d}_2^T\\vdots\\mathbf{d}_P^T<br>\end{array}\right)$, $\mathbf{Y} = \left(\begin{array}{cc}<br>    \mathbf{y}_1^T\\mathbf{y}_2^T\\vdots\\mathbf{y}_P^T<br>\end{array}\right)$, and $\mathbf{U} = \left(\begin{array}{cc}<br>    \mathbf{u}_1^T\\mathbf{u}_2^T\\vdots\\mathbf{u}_P^T<br>\end{array}\right)$</p><p>The algorithm is:</p><script type="math/tex; mode=display">\begin{aligned}    &\text{Given a training dataset} \{(\mathbf{X}, \mathbf{D})\}\\    &\text{Set learning parameter }\alpha\\    &\text{Initialize $\mathbf{W}$ and $\mathbf{b}$}\\    &\text{Repeat until convergence:}\\    &\qquad \mathbf{U} = \mathbf{X}\mathbf{W} + \mathbf{B}\\    &\qquad \mathbf{Y} = f(\mathbf{U}) = \frac{1}{1+e^{-\mathbf{U}}}\\    &\qquad\nabla_\mathbf{U}J = -(\mathbf{D} - \mathbf{Y})\cdot f'(\mathbf{U})\\    &\qquad\nabla_\mathbf{W}J = \mathbf{X}^T\nabla_\mathbf{U}J\\    &\qquad\nabla_\mathbf{b}J = (\nabla_\mathbf{U}J)^T\mathbf{1}_P\\    &\qquad\mathbf{W}\leftarrow\mathbf{W} - \alpha\nabla_\mathbf{W}J\\    &\qquad\mathbf{b}\leftarrow\mathbf{b} - \alpha\nabla_\mathbf{b}J\end{aligned}</script><h2 id="Conclusion-for-Perceptron-Layer"><a href="#Conclusion-for-Perceptron-Layer" class="headerlink" title="Conclusion for Perceptron Layer"></a>Conclusion for Perceptron Layer</h2><p><img src="../figures/perceptron%20layer.png" alt="perceptron layer"></p><h1 id="Softmax-Layer"><a href="#Softmax-Layer" class="headerlink" title="Softmax Layer"></a>Softmax Layer</h1><p>Softmax layer is the extension of logistic regression to <strong>multiclass classification</strong> problem, which is also known as <em>multinomial logistic regression</em>.</p><p>Each neuron in the softmax layer corresponds to one class label. The activation of a neuron gives the probability of the input belonging to that class label. The $K$ neurons in the softmax layer performs $K$ class classification and represent $K$ classes.</p><p>The activation of each neuron $k$ estimates the probability $P(y=k|x)$ that the input $\mathbf{x}$ belongs to the class $k$:</p><script type="math/tex; mode=display">P(y = k|\mathbf{x}) = f(u_k) = \frac{e_{u_k}}{\sum_{k'=1}^Ke^{u_{k'}}}</script><p>where $u_k = \mathbf{w}_k^T\mathbf{x} + b_k$, and $\mathbf{w}_k$ is weight vector and $b_k$ is bias of neuron $k$.</p><p>The above function $f$ is known as <strong>softmax activation function</strong>.</p><p>The ouput $y$ donotes the class label of the input pattern, which is given by</p><script type="math/tex; mode=display">y = \argmax_k P(y=k|\mathbf{x}) = \argmax_k f(u_k)</script><p>That is, the class label is assigned to the class with the maximum activation.</p><h2 id="SGD-for-softmax-layer"><a href="#SGD-for-softmax-layer" class="headerlink" title="SGD for softmax layer"></a>SGD for softmax layer</h2><p>Given a training pattern $(\mathbf{x}, d)$ where $\mathbf{x}\in \mathbb{R}^n$ and $d\in {1,2,\dots,K}$. The cost function for learning is by the <em>multiclass cross-entropy</em>:</p><script type="math/tex; mode=display">J = -\sum_{k=1}^K 1(d=k)log(f(u_k))</script><p>where $u_k$ is the synaptic input to the $k$th neuron. </p><p>The cost function can also be written as</p><script type="math/tex; mode=display">J = -\log(f(u_d))</script><p>where $d$ is the target label of input $\mathbf{x}$.</p><p>The gradient with respect to $u_k$ is given by</p><script type="math/tex; mode=display">\frac{\partial J}{\partial u_k} = -\frac{1}{f(u_d)}\frac{\partial f(u_d)}{\partial u_k}</script><p>where</p><script type="math/tex; mode=display">\frac{\partial f(u_d)}{\partial u_k} = \frac{\partial}{\partial u_k}\left(\frac{e_{u_d}}{\sum_{k'=1}^K e^{u_{k'}}}\right)</script><p>The above differentiation need to be considered separately for $k=d$ and for $k\neq d$.</p><p>If $k = d$:</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial f(u_d)}{\partial u_k}&=\frac{\partial}{\partial u_k}\left(\frac{u^{u_k}}{\sum_{k'=1}^Ke^{u_{k'}}}\right)\\    &=\frac{\left(\sum_{k'=1}^Ke^{u_{k'}}\right)e^{u_k} - e^{u_k}e^{u_k}}{\left(\sum_{k'=1}^Ke^{u_{k'}}\right)^2}\\    &=\frac{e^{u_k}}{\sum_{k'=1}^Ke^{u_{k'}}}\left(1-\frac{e^{u_k}}{\sum_{k'=1}^Ke^{u_{k'}}}\right)\\    &=f(u_k)(1-f(u_k))\\    &=f(u_d)(1(k=d) - f(u_k))\end{aligned}</script><p>If $k \neq d$:</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial f(u_d)}{\partial u_k} &= \frac{\partial}{\partial u_k}\left(\frac{e^{u_d}}{\sum_{k'=1}^Ke^{u_{k'}}}\right)\\    &=-\frac{e^{u_d}e^{u_k}}{\left(\sum_{k'=1}^Ke^{u_{k'}}\right)^2}\\    &=-f(u_d)f(u_k)\\    &=f(u_d)(1(k=d) - f(u_k))\end{aligned}</script><p>Thus</p><script type="math/tex; mode=display">\frac{\partial f(u_d)}{\partial u_k} = f(u_d)(1(d=k) - f(u_k))\\\frac{\partial J}{\partial u_k} = -\frac{1}{f(u_d)}\frac{\partial f(u_d)}{\partial u_k} = -(1(d=k)-f(u_k))</script><p>Gradient $J$ with respect to $\mathbf{u}$:</p><script type="math/tex; mode=display">\nabla_{\mathbf{u}}J = \left(\begin{matrix}    \nabla_{u_1}J\\\nabla_{u_2}J\\\vdots\\\nabla_{u_K}J\end{matrix}\right) = -\left(\begin{matrix}    1(d=1)-f(u_1)\\1(d=2)-f(u_2)\\\vdots\\1(d=K)-f(u_K)\end{matrix}\right) = -(1(\mathbf{k}=d) - f(\mathbf{u}))</script><p>where $\mathbf{k} = (1\quad2\quad\dots\quad K)^T$</p><p>Note that $1(\mathbf{k} = d)$ is a one-hot vector where the element corresponding to the target label $d$ is “1” and elsewhere is “0”.</p><h2 id="GD-for-softmax-layer"><a href="#GD-for-softmax-layer" class="headerlink" title="GD for softmax layer"></a>GD for softmax layer</h2><p>Given a set of patterns ${(\mathbf{x}<em>p, d_p)}</em>{p=1}^P$ where $\mathbf{x}_p\in \mathbb{R}^n$ and $d_p\in {1,2,\dots,K}$.</p><p>The cost function of the <em>softmax layer</em> is given by the <em>multiclass cross-entropy</em>:</p><script type="math/tex; mode=display">J = -\sum_{p=1}^P\left(\sum_{k=1}^K 1(d=k)log(f(u_k))\right)</script><p>where $u_{pk}$ is the synaptic input to the $k$ neuron for input $\mathbf{x}_p$. The cost function $J$ can also be written as</p><script type="math/tex; mode=display">J = -\sum_{p=1}^P\log(f(u_{p{d_p}})) = \sum_{p=1}^P J_p</script><p>where $J<em>p = -\log(f(u</em>{pd_p}))$ is the cross-entropy for the $p$th pattern.</p><script type="math/tex; mode=display">\nabla_\mathbf{U}J = \left(\begin{matrix}    (\nabla_{\mathbf{u}_1}J)^T\\    (\nabla_{\mathbf{u}_2}J)^T\\    \vdots\\    (\nabla_{\mathbf{u}_P}J)^T\end{matrix}\right) = \left(\begin{matrix}    (\nabla_{\mathbf{u}_1}J_1)^T\\    (\nabla_{\mathbf{u}_2}J_2)^T\\    \vdots\\    (\nabla_{\mathbf{u}_P}J_P)^T\end{matrix}\right) = \left(\begin{matrix}    (1(\mathbf{k}=d_1) - f(\mathbf{u}_1))^T\\    (1(\mathbf{k}=d_2) - f(\mathbf{u}_2))^T\\    \vdots\\    (1(\mathbf{k}=d_K) - f(\mathbf{u}_K))^T\end{matrix}\right)</script><script type="math/tex; mode=display">\nabla_\mathbf{U}J = -(\mathbf{K} - f(\mathbf{U}))</script><p>where $K = \left(\begin{matrix}<br>    1(\mathbf(k)=d_1)^T\<br>    1(\mathbf(k)=d_2)^T\<br>    \vdots\<br>    1(\mathbf(k)=d_P)^T<br>\end{matrix}\right)$ is a matrix with every row is a one-hot vector.</p><h2 id="Conclusion-for-softmax-layer"><a href="#Conclusion-for-softmax-layer" class="headerlink" title="Conclusion for softmax layer"></a>Conclusion for softmax layer</h2><p><img src="../figures/softmax.png" alt="Softmax"></p><h1 id="Initialization-of-weights"><a href="#Initialization-of-weights" class="headerlink" title="Initialization of weights"></a>Initialization of weights</h1><p>Random initialization is inefficient. At the initialization, it is desirable that weights are small and near zero</p><ul><li>to operate in the linear region of the activation function</li><li>to preserve the variance of activations and gradients</li></ul><p>Two methods:</p><ul><li>Using a uniform distribution within specified limits</li><li>Using a truncated normal distribution</li></ul><h2 id="Initialization-from-a-uniform-distribution"><a href="#Initialization-from-a-uniform-distribution" class="headerlink" title="Initialization from a uniform distribution"></a>Initialization from a uniform distribution</h2><p>For sigmoid activations:</p><script type="math/tex; mode=display">w \sim Uniform\left[-\frac{4\sqrt{6}}{\sqrt{n_{in} + n_{out}}}, +\frac{4\sqrt{6}}{\sqrt{n_{in} + n_{out}}}\right]</script><p>For others:</p><script type="math/tex; mode=display">w \sim Uniform\left[-\frac{\sqrt{6}}{\sqrt{n_{in} + n_{out}}}, +\frac{\sqrt{6}}{\sqrt{n_{in} + n_{out}}}\right]</script><p>where $n<em>{in}$ is the number of input nodes and $n</em>{out}$ is the number of neurons in the layer.</p><p>$Uniform$ draws a uniformly distributed number within limits.</p><h2 id="Initialization-from-a-truncated-normal-distribution"><a href="#Initialization-from-a-truncated-normal-distribution" class="headerlink" title="Initialization from a truncated normal distribution"></a>Initialization from a truncated normal distribution</h2><script type="math/tex; mode=display">w\sim truncated\_normal\left[mean=0, std=\frac{1}{\sqrt{n_{in}}}\right]</script><p>In the truncated normal, the samples that are two s.d. away from the center are discarded and resampled again.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#neuron-layer&quot;&gt;Neuron Layer&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#weight-matrix-of-a-layer&quot;&gt;Weight matrix of a layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=</summary>
      
    
    
    
    <category term="Deep Learning" scheme="http://example.com/categories/Deep-Learning/"/>
    
    
    <category term="Neuron Layer" scheme="http://example.com/tags/Neuron-Layer/"/>
    
  </entry>
  
</feed>
