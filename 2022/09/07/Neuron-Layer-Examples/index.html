<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Example 1 Output of perceptron layer  Solution   Example 2 GD of a softmax classification  Solution   Example 3 Softmax classification of iris data  Solution   Example 4 GD of a perceptron layer  Sol">
<meta property="og:type" content="article">
<meta property="og:title" content="Neuron Layer Examples">
<meta property="og:url" content="http://example.com/2022/09/07/Neuron-Layer-Examples/index.html">
<meta property="og:site_name" content="LYTinn">
<meta property="og:description" content="Example 1 Output of perceptron layer  Solution   Example 2 GD of a softmax classification  Solution   Example 3 Softmax classification of iris data  Solution   Example 4 GD of a perceptron layer  Sol">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/3.2_1.png">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/3.2_2.png">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/3.2_3.png">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/3.2_1.png">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/3.2_2.png">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/GD-perceptron-layer.png">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/3.4_1.png">
<meta property="og:image" content="http://example.com/figures/dl_tutorial3/3.4_2.png">
<meta property="article:published_time" content="2022-09-07T01:43:56.000Z">
<meta property="article:modified_time" content="2022-09-07T01:46:09.326Z">
<meta property="article:author" content="Run">
<meta property="article:tag" content="examples">
<meta property="article:tag" content="Neuron Layer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/figures/dl_tutorial3/3.2_1.png">

<link rel="canonical" href="http://example.com/2022/09/07/Neuron-Layer-Examples/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Neuron Layer Examples | LYTinn</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="LYTinn" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">LYTinn</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">My learning notes</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/09/07/Neuron-Layer-Examples/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Run">
      <meta itemprop="description" content="This blog will record my thinking and learning notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LYTinn">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Neuron Layer Examples
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-09-07 09:43:56 / Modified: 09:46:09" itemprop="dateCreated datePublished" datetime="2022-09-07T09:43:56+08:00">2022-09-07</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <ul>
<li><a href="#example-1-output-of-perceptron-layer">Example 1 Output of perceptron layer</a>
<ul>
<li><a href="#solution">Solution</a></li>
</ul>
</li>
<li><a href="#example-2-gd-of-a-softmax-classification">Example 2 GD of a softmax classification</a>
<ul>
<li><a href="#solution-1">Solution</a></li>
</ul>
</li>
<li><a href="#example-3-softmax-classification-of-iris-data">Example 3 Softmax classification of iris data</a>
<ul>
<li><a href="#solution-2">Solution</a></li>
</ul>
</li>
<li><a href="#example-4-gd-of-a-perceptron-layer">Example 4 GD of a perceptron layer</a>
<ul>
<li><a href="#solution-3">Solution</a></li>
</ul>
</li>
</ul>
<h1 id="example-1-output-of-perceptron-layer"><a class="markdownIt-Anchor" href="#example-1-output-of-perceptron-layer"></a> Example 1 Output of perceptron layer</h1>
<p>A perceptron layer of 3 neurons shown in the figure receives 2-dimensional inputs <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">(x_1, x_2)^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>, and has a weight matrix <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi></mrow><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span></span></span> and a bias vector <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">b</span></span></span></span></span> given by</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">W</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.133</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.072</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.155</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.001</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.062</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.072</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{W} = \left(\begin{matrix}
  0.133&amp;0.072&amp;-0.155\\-0.001&amp;0.062&amp;-0.072
\end{matrix}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">3</span><span class="mord">3</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">7</span><span class="mord">2</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">6</span><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">5</span><span class="mord">5</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">7</span><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">b</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.017</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.009</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.069</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{b} = \left(\begin{matrix}
  0.017\\0.009\\0.069
\end{matrix}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">b</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.60004em;vertical-align:-1.55002em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:-3.2550000000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="overlay" style="height:0.3em;width:0.875em;"><svg width='0.875em' height='0.3em' style='width:0.875em' viewBox='0 0 875 300' preserveAspectRatio='xMinYMin'><path d='M291 0 H417 V300 H291 z'/></svg></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">9</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">6</span><span class="mord">9</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:-3.2550000000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="overlay" style="height:0.3em;width:0.875em;"><svg width='0.875em' height='0.3em' style='width:0.875em' viewBox='0 0 875 300' preserveAspectRatio='xMinYMin'><path d='M457 0 H583 V300 H457 z'/></svg></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>Using batch processing, find the output for input patterns:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.5</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1.66</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1.0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.51</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.78</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.65</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0.04</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\left(\begin{matrix}
  0.5\\-1.66
\end{matrix}\right),
\left(\begin{matrix}
  -1.0\\-0.51
\end{matrix}\right),
\left(\begin{matrix}
  0.78\\-0.65
\end{matrix}\right),
\left(\begin{matrix}
  0.04\\-0.2
\end{matrix}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span><span class="mord">.</span><span class="mord">6</span><span class="mord">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span><span class="mord">.</span><span class="mord">0</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mord">8</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">6</span><span class="mord">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">4</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<h3 id="solution"><a class="markdownIt-Anchor" href="#solution"></a> Solution</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># input data</span></span><br><span class="line">X = np.array([[<span class="number">0.5</span>,-<span class="number">1.66</span>],[-<span class="number">1.0</span>,-<span class="number">0.51</span>],[<span class="number">0.78</span>,-<span class="number">0.65</span>],[<span class="number">0.04</span>,-<span class="number">0.2</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(X))</span><br><span class="line"><span class="comment"># define weight and bias</span></span><br><span class="line">W = np.array([[<span class="number">0.133</span>, <span class="number">0.072</span>, -<span class="number">0.155</span>],</span><br><span class="line">             [-<span class="number">0.001</span>, <span class="number">0.062</span>, -<span class="number">0.072</span>]])</span><br><span class="line">b = np.array([<span class="number">0.017</span>, <span class="number">0.009</span>, <span class="number">0.069</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;W:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(W))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(b))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>x:[[ 0.5  -1.66]<br />
[-1.   -0.51]<br />
[ 0.78 -0.65]<br />
[ 0.04 -0.2 ]]<br />
W:[[ 0.133  0.072 -0.155]<br />
[-0.001  0.062 -0.072]]<br />
b:[0.017 0.009 0.069]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define a class for a perceptron layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Layer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.w = tf.Variable(W, dtype=tf.float64)</span><br><span class="line">        self.b = tf.Variable(b, dtype=tf.float64)     </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, x</span>):</span><br><span class="line">        u = tf.matmul(x, self.w) + self.b</span><br><span class="line">        y = tf.sigmoid(u)</span><br><span class="line">        <span class="keyword">return</span> u, y</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Layer()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, \nb: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>w: [[ 0.133  0.072 -0.155]<br />
[-0.001  0.062 -0.072]], <br />
b: [0.017 0.009 0.069]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">u, y = model(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;u: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(u))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(y))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>u: [[ 0.08516 -0.05792  0.11102]<br />
[-0.11549 -0.09462  0.26072]<br />
[ 0.12139  0.02486 -0.0051 ]<br />
[ 0.02252 -0.00052  0.0772 ]]<br />
y: [[0.52127714 0.48552405 0.52772653]<br />
[0.47115955 0.47636263 0.56481328]<br />
[0.53031029 0.50621468 0.498725  ]<br />
[0.50562976 0.49987    0.51929042]]</p>
</blockquote>
<h1 id="example-2-gd-of-a-softmax-classification"><a class="markdownIt-Anchor" href="#example-2-gd-of-a-softmax-classification"></a> Example 2 GD of a softmax classification</h1>
<p>Train a softmax regression layer of neurons to perform the following classification:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mn>0.94</mn><mspace width="1em"/><mn>0.18</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class A</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><mo>−</mo><mn>0.58</mn><mspace width="1em"/><mo>−</mo><mn>0.53</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class B</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><mo>−</mo><mn>0.23</mn><mspace width="1em"/><mo>−</mo><mn>0.31</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class B</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><mn>0.42</mn><mspace width="1em"/><mo>−</mo><mn>0.44</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class A</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><mn>0.5</mn><mspace width="1em"/><mo>−</mo><mn>1.66</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class C</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><mo>−</mo><mn>1.0</mn><mspace width="1em"/><mo>−</mo><mn>0.51</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class B</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><mn>0.78</mn><mspace width="1em"/><mo>−</mo><mn>0.65</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class A</mtext><mspace linebreak="newline"></mspace><mo stretchy="false">(</mo><mn>0.04</mn><mspace width="1em"/><mo>−</mo><mn>0.20</mn><mo stretchy="false">)</mo><mo>→</mo><mtext>class C</mtext></mrow><annotation encoding="application/x-tex">(0.94\quad0.18)\rightarrow \text{class A}\\
(-0.58\quad-0.53)\rightarrow \text{class B}\\
(-0.23\quad-0.31)\rightarrow \text{class B}\\
(0.42\quad-0.44)\rightarrow \text{class A}\\
(0.5\quad-1.66)\rightarrow \text{class C}\\
(-1.0\quad-0.51)\rightarrow \text{class B}\\
(0.78\quad-0.65)\rightarrow \text{class A}\\
(0.04\quad-0.20)\rightarrow \text{class C}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">4</span><span class="mspace" style="margin-right:1em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">8</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class A</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">8</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">3</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class B</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">3</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class B</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mord">2</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mord">4</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class A</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">6</span><span class="mord">6</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class C</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mord">.</span><span class="mord">0</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class B</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mord">8</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">6</span><span class="mord">5</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class A</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">4</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class="mord">class C</span></span></span></span></span></span></p>
<p>use a learning factor <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.05</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span></span></span></span>.</p>
<h3 id="solution-2"><a class="markdownIt-Anchor" href="#solution-2"></a> Solution</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set parameters of the layer and for learning</span></span><br><span class="line">num_epochs = <span class="number">3000</span></span><br><span class="line">num_inputs = <span class="number">2</span></span><br><span class="line">num_classes = <span class="number">3</span></span><br><span class="line">lr = <span class="number">0.05</span></span><br><span class="line"></span><br><span class="line">SEED = <span class="number">10</span></span><br><span class="line">np.random.seed(SEED)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prepare inputs and outputs</span></span><br><span class="line">X = np.array([[<span class="number">0.94</span>, <span class="number">0.18</span>],[-<span class="number">0.58</span>, -<span class="number">0.53</span>],[-<span class="number">0.23</span>, -<span class="number">0.31</span>],[<span class="number">0.42</span>, -<span class="number">0.44</span>],</span><br><span class="line">              [<span class="number">0.5</span>, -<span class="number">1.66</span>],[-<span class="number">1.0</span>, -<span class="number">0.51</span>],[<span class="number">0.78</span>, -<span class="number">0.65</span>],[<span class="number">0.04</span>, -<span class="number">0.20</span>]])</span><br><span class="line">Y = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">K = np.array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]]).astype(<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line"><span class="built_in">print</span>(Y)</span><br><span class="line"><span class="built_in">print</span>(lr)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>[[ 0.94  0.18]<br />
[-0.58 -0.53]<br />
[-0.23 -0.31]<br />
[ 0.42 -0.44]<br />
[ 0.5  -1.66]<br />
[-1.   -0.51]<br />
[ 0.78 -0.65]<br />
[ 0.04 -0.2 ]]<br />
[0 1 1 0 2 1 0 2]<br />
0.05</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define the class for the softmax layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Softmax_Layer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, no_inputs, no_classes</span>):</span><br><span class="line">        self.w = tf.Variable(np.random.rand(no_inputs, no_classes), dtype=tf.float64)</span><br><span class="line">        self.b = tf.Variable(tf.zeros([no_classes], dtype=tf.float64))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, x</span>):</span><br><span class="line">        u = tf.matmul(x, self.w) + self.b</span><br><span class="line">        p = tf.exp(u)/tf.reduce_sum(tf.exp(u), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        y = tf.argmax(p, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> u, p, y</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">p, k, y</span>):</span><br><span class="line">    entropy = -tf.reduce_sum(tf.math.log(p)*k)</span><br><span class="line">    error = tf.reduce_sum(tf.cast(tf.not_equal(tf.argmax(k,<span class="number">1</span>),y),tf.int32))</span><br><span class="line">    <span class="keyword">return</span> entropy, error</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, inputs, k, learning_rate</span>):</span><br><span class="line">    _, p, y = model(inputs)</span><br><span class="line">    grad_u = -(k-p)</span><br><span class="line">    grad_w = tf.matmul(tf.transpose(inputs), grad_u)</span><br><span class="line">    grad_b = tf.reduce_sum(grad_u, axis=<span class="number">0</span>) <span class="comment"># axis refers to the dimension of tensor</span></span><br><span class="line">    </span><br><span class="line">    model.w.assign_sub(learning_rate * grad_w)</span><br><span class="line">    model.b.assign_sub(learning_rate * grad_b)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> grad_u, grad_w, grad_b</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize the layer</span></span><br><span class="line">model = Softmax_Layer(num_inputs, num_classes)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br></pre></td></tr></table></figure>
<blockquote></blockquote>
<p>w: [[0.44183317 0.43401399 0.61776698]<br />
[0.51313824 0.65039718 0.60103895]], b: [0. 0. 0.]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">loss_, err_ = [], []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    u_, p_, y_ = model(X)</span><br><span class="line">    l_, e_ = loss(p_, K, y_)</span><br><span class="line">    grad_u_, grad_w_, grad_b_ = train(model, X, K, lr)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (epoch == <span class="number">0</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;iter: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;u: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(u_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;p: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(p_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;y: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(y_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;entropy: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(l_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;error: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(e_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;grad_u: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grad_u_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;grad_w: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grad_w_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;grad_b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grad_b_))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br><span class="line">  </span><br><span class="line">    loss_.append(l_), err_.append(e_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> epoch%<span class="number">100</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch:&#123;&#125;, loss:&#123;&#125;, error:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch,loss_[epoch], err_[epoch]))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>iter: 1<br />
u: [[ 0.50768807  0.52504465  0.68888797]<br />
[-0.52822651 -0.59643862 -0.67685549]<br />
[-0.26069449 -0.30144634 -0.32840848]<br />
[-0.04021089 -0.10388888 -0.00499501]<br />
[-0.6308929  -0.86265233 -0.68884117]<br />
[-0.70353368 -0.76571656 -0.92429684]<br />
[ 0.01109002 -0.08422725  0.09118292]<br />
[-0.08495432 -0.11271888 -0.09549711]]<br />
p: [[0.31092953 0.31637331 0.37269716]<br />
[0.35766004 0.33407677 0.30826319]<br />
[0.34547147 0.33167587 0.32285266]<br />
[0.33623047 0.31548744 0.34828209]<br />
[0.36538548 0.28980071 0.34481382]<br />
[0.36474817 0.34275787 0.29249396]<br />
[0.33417186 0.30379045 0.36203769]<br />
[0.33759491 0.32835067 0.33405442]]<br />
y: [2 0 0 2 0 0 2 0]<br />
entropy: 8.78616183666182<br />
error: 8<br />
grad_u: [[-0.68907047  0.31637331  0.37269716]<br />
[ 0.35766004 -0.66592323  0.30826319]<br />
[ 0.34547147 -0.66832413  0.32285266]<br />
[-0.66376953  0.31548744  0.34828209]<br />
[ 0.36538548  0.28980071 -0.65518618]<br />
[ 0.36474817 -0.65724213  0.29249396]<br />
[-0.66582814  0.30379045  0.36203769]<br />
[ 0.33759491  0.32835067 -0.66594558]]<br />
grad_w: [[-1.90130829  2.02207871 -0.12077043]<br />
[-0.55592222  0.0692429   0.48667931]]<br />
grad_b: [-0.24780807 -0.43768692  0.68549499]<br />
w: [[0.53689859 0.33291006 0.6238055 ]<br />
[0.54093435 0.64693504 0.57670499]], b: [ 0.0123904   0.02188435 -0.03427475]<br />
epoch:0, loss:8.78616183666182, error:8<br />
epoch:100, loss:2.8684515778635955, error:1<br />
epoch:200, loss:2.2883120189878925, error:1<br />
epoch:300, loss:1.9730210412198046, error:0<br />
epoch:400, loss:1.7592913803333123, error:0<br />
epoch:500, loss:1.5998765664851753, error:0<br />
epoch:600, loss:1.4740705847133975, error:0<br />
epoch:700, loss:1.370955701326433, error:0<br />
epoch:800, loss:1.2841033606723224, error:0<br />
epoch:900, loss:1.2094309742118017, error:0<br />
epoch:1000, loss:1.144196610636459, error:0<br />
epoch:1100, loss:1.0864768286088007, error:0<br />
epoch:1200, loss:1.034874189355273, error:0<br />
epoch:1300, loss:0.9883435309164786, error:0<br />
epoch:1400, loss:0.9460838064030327, error:0<br />
epoch:1500, loss:0.9074680758355147, error:0<br />
epoch:1600, loss:0.8719966867182616, error:0<br />
epoch:1700, loss:0.8392650728596022, error:0<br />
epoch:1800, loss:0.8089410612158957, error:0<br />
epoch:1900, loss:0.780748532875915, error:0<br />
epoch:2000, loss:0.7544554326694685, error:0<br />
epoch:2100, loss:0.7298648182889294, error:0<br />
epoch:2200, loss:0.7068080743670997, error:0<br />
epoch:2300, loss:0.6851396950546537, error:0<br />
epoch:2400, loss:0.6647332206708897, error:0<br />
epoch:2500, loss:0.6454780355864276, error:0<br />
epoch:2600, loss:0.6272768172078264, error:0<br />
epoch:2700, loss:0.6100434831452572, error:0<br />
epoch:2800, loss:0.5937015238244387, error:0<br />
epoch:2900, loss:0.5781826364208404, error:0</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(loss_[-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>w: [[ 14.24025851 -13.00690374   0.26025937]<br />
[  4.56356541  -1.94667656  -0.85231447]], b: [-0.52891834 -0.47039985  0.99931818]<br />
loss: 0.5635695814410673</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plot_pred = plt.plot(X[Y==<span class="number">0</span>,<span class="number">0</span>], X[Y==<span class="number">0</span>,<span class="number">1</span>], <span class="string">&#x27;b^&#x27;</span>, label=<span class="string">&#x27;class 1&#x27;</span>)</span><br><span class="line">plot_original = plt.plot(X[Y==<span class="number">1</span>,<span class="number">0</span>], X[Y==<span class="number">1</span>,<span class="number">1</span>], <span class="string">&#x27;ro&#x27;</span>, label=<span class="string">&#x27;class 2&#x27;</span>)</span><br><span class="line">plot_original = plt.plot(X[Y==<span class="number">2</span>,<span class="number">0</span>], X[Y==<span class="number">2</span>,<span class="number">1</span>], <span class="string">&#x27;gx&#x27;</span>, label=<span class="string">&#x27;class 3&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$x_1$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;$x_2$&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;data points&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.savefig(<span class="string">&#x27;./figures/3.2_1.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/figures/dl_tutorial3/3.2_1.png" alt="3.21" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(<span class="number">2</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(num_epochs), loss_)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;cross-entropy&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./figures/3.2_2.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/figures/dl_tutorial3/3.2_2.png" alt="3.22" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(<span class="number">3</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(num_epochs), err_)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;classification error&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./figures/3.2_3.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/figures/dl_tutorial3/3.2_3.png" alt="3.23" /></p>
<h1 id="example-3-softmax-classification-of-iris-data"><a class="markdownIt-Anchor" href="#example-3-softmax-classification-of-iris-data"></a> Example 3 Softmax classification of iris data</h1>
<p>Iris data has three classes of iris flower. There are four features:</p>
<ul>
<li>Sepal length</li>
<li>Sepal width</li>
<li>Petal Length</li>
<li>Petal width</li>
</ul>
<p>Using softmax classification to classify the iris data.</p>
<h3 id="solution-3"><a class="markdownIt-Anchor" href="#solution-3"></a> Solution</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set the parameters</span></span><br><span class="line">no_epochs = <span class="number">2500</span></span><br><span class="line">lr = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">SEED = <span class="number">100</span></span><br><span class="line">np.random.seed(SEED)</span><br><span class="line">tf.random.set_seed(SEED)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prepare iris dataset</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">no_inputs = <span class="number">4</span></span><br><span class="line">no_outputs = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># input data</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris.data -= np.mean(iris.data, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">no_data = <span class="built_in">len</span>(iris.data)</span><br><span class="line"></span><br><span class="line">X = iris.data</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert the targets into one-hot matrix</span></span><br><span class="line">Y = np.zeros((no_data, no_outputs))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(no_data):</span><br><span class="line">    Y[i, iris.target[i]] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(np.shape(X))</span><br><span class="line"><span class="built_in">print</span>(np.shape(Y))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>(150, 4)<br />
(150, 3)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define a class of softmax layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SoftmaxLayer</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, no_inputs, no_outputs</span>):</span><br><span class="line">        w_init = tf.random_normal_initializer()</span><br><span class="line">        self.w = tf.Variable(w_init(shape=(no_inputs,no_outputs), dtype=tf.float64))</span><br><span class="line">        b_init = tf.zeros_initializer()</span><br><span class="line">        self.b = tf.Variable(b_init(shape=(no_outputs), dtype=tf.float64))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, x</span>):</span><br><span class="line">        u = tf.matmul(x, self.w) + self.b</span><br><span class="line">        <span class="keyword">return</span> tf.exp(u)/tf.reduce_sum(tf.exp(u), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">targets, logits</span>):</span><br><span class="line">    t_float = tf.cast(targets, tf.float64)</span><br><span class="line">    losses = -tf.reduce_mean(tf.reduce_sum(tf.math.log(logits)*targets, axis=<span class="number">1</span>))</span><br><span class="line">    class_err = tf.reduce_sum(tf.cast(tf.not_equal(tf.argmax(logits, axis=<span class="number">1</span>), tf.argmax(targets, axis=<span class="number">1</span>)), dtype=tf.int32))</span><br><span class="line">    <span class="keyword">return</span> losses, class_err</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, inputs, outputs, learning_rate</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> t:</span><br><span class="line">        current_loss, current_err = loss(outputs, model(inputs))</span><br><span class="line">    dw, db = t.gradient(current_loss, [model.w, model.b])</span><br><span class="line">    model.w.assign(model.w - learning_rate * dw)</span><br><span class="line">    model.b.assign(model.b - learning_rate * db)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># initialize the softmax layer</span></span><br><span class="line">model = SoftmaxLayer(no_inputs, no_outputs)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.w.numpy(), model.b.numpy())</span><br></pre></td></tr></table></figure>
<blockquote>
<p>[[ 0.00470517  0.00424244 -0.0228833 ]<br />
[-0.0086293  -0.03198624  0.05250187]<br />
[ 0.10071415 -0.00131456 -0.00903195]<br />
[-0.01193019 -0.04326576 -0.04804788]] [0. 0. 0.]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train the model</span></span><br><span class="line">entropy, err = [], []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(no_epochs):</span><br><span class="line">    entropy_, err_ = loss(Y, model(X))</span><br><span class="line">    entropy.append(entropy_), err.append(err_)</span><br><span class="line"></span><br><span class="line">    train(model, X, Y, learning_rate=lr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch %2d:  loss=%2.5f:  error=%3d&#x27;</span>%(epoch, entropy[-<span class="number">1</span>], err[-<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">entropy_, err_ = loss(Y, model(X))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test error=%3d&#x27;</span>%err_)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Epoch  0:  loss=1.20477:  error=140<br />
Epoch 100:  loss=0.16400:  error=  5<br />
Epoch 200:  loss=0.11847:  error=  4<br />
Epoch 300:  loss=0.09852:  error=  3<br />
Epoch 400:  loss=0.08708:  error=  3<br />
Epoch 500:  loss=0.07958:  error=  2<br />
Epoch 600:  loss=0.07424:  error=  2<br />
Epoch 700:  loss=0.07023:  error=  2<br />
Epoch 800:  loss=0.06710:  error=  2<br />
Epoch 900:  loss=0.06459:  error=  2<br />
Epoch 1000:  loss=0.06252:  error=  2<br />
Epoch 1100:  loss=0.06078:  error=  3<br />
Epoch 1200:  loss=0.05930:  error=  3<br />
Epoch 1300:  loss=0.05802:  error=  3<br />
Epoch 1400:  loss=0.05690:  error=  3<br />
Epoch 1500:  loss=0.05592:  error=  3<br />
Epoch 1600:  loss=0.05504:  error=  3<br />
Epoch 1700:  loss=0.05426:  error=  3<br />
Epoch 1800:  loss=0.05355:  error=  3<br />
Epoch 1900:  loss=0.05291:  error=  3<br />
Epoch 2000:  loss=0.05233:  error=  3<br />
Epoch 2100:  loss=0.05179:  error=  3<br />
Epoch 2200:  loss=0.05130:  error=  3<br />
Epoch 2300:  loss=0.05085:  error=  3<br />
Epoch 2400:  loss=0.05043:  error=  3<br />
test error=  3</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print learned weights</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w: %s, b: %s&#x27;</span>%(model.w.numpy(), model.b.numpy()))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>w: [[-5.64468184e-01  1.29034580e+00 -7.39813302e-01]<br />
[ 2.43509283e+00  1.08464962e-03 -2.42429116e+00]<br />
[-5.19366825e+00 -2.52485178e-01  5.53652107e+00]<br />
[-2.38732752e+00 -2.88848158e+00  5.17256527e+00]], b: [-0.98272709  5.52615415 -4.54342706]</p>
</blockquote>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># plot learning curves</span></span><br><span class="line">plt.figure(<span class="number">2</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(no_epochs), entropy)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;cross-entropy&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./figures/3.3_1.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">3</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(no_epochs), np.array(err))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;classification error&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./figures/3.3_2.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/figures/dl_tutorial3/3.2_1.png" alt="3.21" /><br />
<img src="/figures/dl_tutorial3/3.2_2.png" alt="3.22" /></p>
<h1 id="example-4-gd-of-a-perceptron-layer"><a class="markdownIt-Anchor" href="#example-4-gd-of-a-perceptron-layer"></a> Example 4 GD of a perceptron layer</h1>
<p>Design a perceptron layer to perform the following mapping using GD learning and learning rate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\alpha=0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span></span></span></span>:<br />
<img src="/figures/dl_tutorial3/GD-perceptron-layer.png" alt="GD of a perceptron layer" /></p>
<h3 id="solution-4"><a class="markdownIt-Anchor" href="#solution-4"></a> Solution</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set the parameter for the layer and training</span></span><br><span class="line">no_features = <span class="number">3</span></span><br><span class="line">no_labels = <span class="number">2</span></span><br><span class="line">no_data = <span class="number">8</span></span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.1</span></span><br><span class="line">no_iters = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line">SEED = <span class="number">10</span></span><br><span class="line">np.random.seed(SEED)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate training data</span></span><br><span class="line">X = np.random.rand(no_data, no_features)</span><br><span class="line">Y = np.zeros((no_data, no_labels))</span><br><span class="line">Y[:,<span class="number">0</span>] = (X[:,<span class="number">0</span>] + X[:,<span class="number">1</span>]**<span class="number">2</span> + X[:, <span class="number">2</span>]**<span class="number">3</span> + np.random.rand(no_data))/<span class="number">4</span></span><br><span class="line">Y[:,<span class="number">1</span>] = (X[:,<span class="number">0</span>] + X[:,<span class="number">1</span>] + X[:, <span class="number">2</span>] + X[:,<span class="number">0</span>]*X[:,<span class="number">1</span>]*X[:,<span class="number">2</span>] + np.random.rand(no_data))/<span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(X))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Y = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(Y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;alpha = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(lr))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>X = [[0.77132064 0.02075195 0.63364823]<br />
[0.74880388 0.49850701 0.22479665]<br />
[0.19806286 0.76053071 0.16911084]<br />
[0.08833981 0.68535982 0.95339335]<br />
[0.00394827 0.51219226 0.81262096]<br />
[0.61252607 0.72175532 0.29187607]<br />
[0.91777412 0.71457578 0.54254437]<br />
[0.14217005 0.37334076 0.67413362]]<br />
Y = [[0.36700015 0.46890243]<br />
[0.36067172 0.37505132]<br />
[0.34976828 0.24872748]<br />
[0.48444787 0.41710316]<br />
[0.36332573 0.28887784]<br />
[0.43984029 0.51677508]<br />
[0.59832905 0.51552032]<br />
[0.27739117 0.37034263]]<br />
alpha = 0.1</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Perceptron_Layer</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, no_features, no_labels</span>):</span><br><span class="line">        self.w = tf.Variable(np.random.rand(no_features, no_labels)*<span class="number">0.05</span>, dtype=tf.float64)</span><br><span class="line">        self.b = tf.Variable(tf.zeros([no_labels], dtype=tf.float64))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, x</span>):</span><br><span class="line">        u = tf.matmul(x, self.w) + self.b</span><br><span class="line">        y = tf.sigmoid(u)</span><br><span class="line">        <span class="keyword">return</span> u, y</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">predicted_y, target_y</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(tf.reduce_sum(tf.square(target_y - predicted_y), axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, inputs, outputs, learning_rate</span>):</span><br><span class="line">    _, y = model(inputs)</span><br><span class="line">    dy = y*(<span class="number">1</span> - y)</span><br><span class="line">    grad_u = -(outputs - y)*dy</span><br><span class="line">    grad_w = tf.matmul(tf.transpose(inputs), grad_u)</span><br><span class="line">    grad_b = tf.reduce_sum(grad_u, axis = <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    model.w.assign_sub(learning_rate * grad_w)</span><br><span class="line">    model.b.assign_sub(learning_rate * grad_b)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dy, grad_u, grad_w, grad_b</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Perceptron_Layer(no_features, no_labels)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>w: [[0.02737931 0.04096435]<br />
[0.00994738 0.04284252]<br />
[0.01758263 0.03773238]], b: [0. 0.]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train the perceptron layer</span></span><br><span class="line">cost = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(no_iters):</span><br><span class="line">    u_, y_ = model(X)</span><br><span class="line">    loss_ = loss(y_, Y)</span><br><span class="line">    dy_, grad_u_, grad_w_, grad_b_ = train(model, X, Y, lr)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (i &lt; <span class="number">2</span> <span class="keyword">or</span> i == no_iters - <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;iter: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;u: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(u_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;y: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(y_))</span><br><span class="line">    </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;m.s.e: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(loss_))</span><br><span class="line">          </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;dy: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(dy_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;grad_u: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grad_u_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;grad_w: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grad_w_))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;grad_b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grad_b_))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br><span class="line">  </span><br><span class="line">    cost.append(loss_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> i%<span class="number">200</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch:&#123;&#125;, loss:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i,cost[i]))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>iter: 1<br />
u: [[0.03246586 0.05639477]<br />
[0.02941309 0.06051367]<br />
[0.01596152 0.04707752]<br />
[0.02599938 0.06895513]<br />
[0.01949109 0.05276747]<br />
[0.02908206 0.06702673]<br />
[0.04177553 0.08868174]<br />
[0.01945932 0.04725543]]<br />
y: [[0.50811575 0.51409496]<br />
[0.50735274 0.5151238 ]<br />
[0.5039903  0.51176721]<br />
[0.50649948 0.51723195]<br />
[0.50487262 0.51318881]<br />
[0.50727    0.51675041]<br />
[0.51044236 0.52215592]<br />
[0.50486468 0.51181166]]<br />
m.s.e: 0.040125181814308984<br />
dy: [[0.24993413 0.24980133]<br />
[0.24994594 0.24977127]<br />
[0.24998408 0.24986153]<br />
[0.24995776 0.24970306]<br />
[0.24997626 0.24982606]<br />
[0.24994715 0.24971942]<br />
[0.24989096 0.24950912]<br />
[0.24997633 0.24986048]]<br />
grad_u: [[ 3.52696045e-02  1.12891542e-02]<br />
[ 3.66623250e-02  3.49860812e-02]<br />
[ 3.85530485e-02  6.57235085e-02]<br />
[ 5.51197077e-03  2.50024655e-02]<br />
[ 3.53833616e-02  5.60387245e-02]<br />
[ 1.68538644e-02 -6.16146671e-06]<br />
[-2.19620871e-02  1.65564230e-03]<br />
[ 5.68629937e-02  3.53475203e-02]]<br />
grad_w: [[0.06117103 0.05689372]<br />
[0.08792995 0.12787342]<br />
[0.10245525 0.1202335 ]]<br />
grad_b: [0.20313508 0.23003693]<br />
w: [[0.0212622  0.03527498]<br />
[0.00115438 0.03005517]<br />
[0.00733711 0.02570903]], b: [-0.02031351 -0.02300369]<br />
epoch:0, loss:0.040125181814308984<br />
iter: 2<br />
u: [[ 0.00075957  0.02111881]<br />
[-0.00216746  0.02417237]<br />
[-0.01398353  0.01118853]<br />
[-0.01064889  0.02522192]<br />
[-0.01367601  0.01342131]<br />
[-0.00431515  0.02779948]<br />
[ 0.00400599  0.04479576]<br />
[-0.01191349  0.0105635 ]]<br />
y: [[0.50018989 0.50527951]<br />
[0.49945813 0.5060428 ]<br />
[0.49650418 0.5027971 ]<br />
[0.4973378  0.50630515]<br />
[0.49658105 0.50335528]<br />
[0.49892122 0.50694942]<br />
[0.5010015  0.51119707]<br />
[0.49702166 0.50264085]]<br />
m.s.e: 0.03653319230796048<br />
dy: [[0.24999996 0.24997213]<br />
[0.24999971 0.24996348]<br />
[0.24998778 0.24999218]<br />
[0.24999291 0.24996025]<br />
[0.24998831 0.24998874]<br />
[0.24999884 0.24995171]<br />
[0.249999   0.24987463]<br />
[0.24999113 0.24999303]]<br />
grad_u: [[ 0.03329743  0.00909326]<br />
[ 0.03469656  0.03274309]<br />
[ 0.03668218  0.06351542]<br />
[ 0.00322239  0.02229695]<br />
[ 0.03331227  0.05361694]<br />
[ 0.01477016 -0.00245594]<br />
[-0.02433179 -0.00108027]<br />
[ 0.05490568  0.03307363]]<br />
grad_w: [[0.05386745 0.04849972]<br />
[0.07892824 0.11736362]<br />
[0.09336808 0.10968475]]<br />
grad_b: [0.18655489 0.21080307]<br />
w: [[ 0.01587546  0.03042501]<br />
[-0.00673844  0.01831881]<br />
[-0.0019997   0.01474056]], b: [-0.038969 -0.044084]<br />
epoch:200, loss:0.01236920027196445<br />
epoch:400, loss:0.009547814990014315<br />
epoch:600, loss:0.007721123872008595<br />
epoch:800, loss:0.006416033024162599<br />
epoch:1000, loss:0.005465560905166514<br />
epoch:1200, loss:0.004769636527024338<br />
epoch:1400, loss:0.0042587309513468456<br />
epoch:1600, loss:0.003882875651306887<br />
epoch:1800, loss:0.0036058395774580592<br />
epoch:2000, loss:0.003401265014784655<br />
epoch:2200, loss:0.0032499348472099436<br />
epoch:2400, loss:0.0031378085266889396<br />
epoch:2600, loss:0.003054605115715101<br />
epoch:2800, loss:0.0029927797035383145<br />
epoch:3000, loss:0.0029467830194868506<br />
epoch:3200, loss:0.0029125249131228717<br />
epoch:3400, loss:0.00288698468227491<br />
epoch:3600, loss:0.002867927335918271<br />
epoch:3800, loss:0.002853696444605626<br />
epoch:4000, loss:0.0028430625060447585<br />
epoch:4200, loss:0.0028351116650964653<br />
epoch:4400, loss:0.002829163852288894<br />
epoch:4600, loss:0.0028247124291994052<br />
epoch:4800, loss:0.002821379599288177<br />
epoch:5000, loss:0.0028188834048013638<br />
epoch:5200, loss:0.002817013258288543<br />
epoch:5400, loss:0.002815611774449621<br />
epoch:5600, loss:0.002814561262001985<br />
epoch:5800, loss:0.0028137736683666154<br />
epoch:6000, loss:0.00281318308672499<br />
epoch:6200, loss:0.002812740167301663<br />
epoch:6400, loss:0.0028124079455334743<br />
epoch:6600, loss:0.002812158725670525<br />
epoch:6800, loss:0.002811971751327711<br />
epoch:7000, loss:0.0028118314633049208<br />
epoch:7200, loss:0.002811726195991678<br />
epoch:7400, loss:0.0028116472015323915<br />
epoch:7600, loss:0.002811587919073888<br />
epoch:7800, loss:0.0028115434273657297<br />
epoch:8000, loss:0.002811510034592676<br />
epoch:8200, loss:0.002811484970959764<br />
epoch:8400, loss:0.0028114661582394566<br />
epoch:8600, loss:0.0028114520369808592<br />
epoch:8800, loss:0.0028114414369319316<br />
epoch:9000, loss:0.002811433479853794<br />
epoch:9200, loss:0.00281142750662048<br />
epoch:9400, loss:0.002811423022529595<br />
epoch:9600, loss:0.0028114196562707195<br />
epoch:9800, loss:0.0028114171291381976<br />
iter: 10000<br />
u: [[-0.65450324 -0.1528308 ]<br />
[-0.46704496 -0.33307843]<br />
[-0.753545   -0.90354437]<br />
[-0.08014989 -0.39632383]<br />
[-0.57954836 -0.68057356]<br />
[-0.21956645 -0.34271239]<br />
[ 0.38789226  0.21420738]<br />
[-0.78656788 -0.69533828]]<br />
y: [[0.34197546 0.4618665 ]<br />
[0.3853159  0.41749178]<br />
[0.32004935 0.28832267]<br />
[0.47997325 0.4021959 ]<br />
[0.35903652 0.3361333 ]<br />
[0.44532785 0.41515076]<br />
[0.5957752  0.55334801]<br />
[0.31290609 0.3328466 ]]<br />
m.s.e: 0.0028114152401259125<br />
dy: [[0.22502824 0.24854584]<br />
[0.23684756 0.24319239]<br />
[0.21761777 0.20519271]<br />
[0.24959893 0.24043436]<br />
[0.2301293  0.22314771]<br />
[0.24701096 0.24280061]<br />
[0.24082711 0.24715399]<br />
[0.21499587 0.22205974]]<br />
grad_u: [[-0.00563126 -0.00174875]<br />
[ 0.00583691  0.0103212 ]<br />
[-0.00646737  0.00812464]<br />
[-0.00111686 -0.00358422]<br />
[-0.00098707  0.01054495]<br />
[ 0.00135549 -0.02467445]<br />
[-0.00061504  0.00934927]<br />
[ 0.00763556 -0.00832636]]<br />
grad_w: [[-4.95517633e-06 -3.08863809e-06]<br />
[-7.26261986e-06 -4.22286188e-06]<br />
[-7.40727970e-06 -4.64967168e-06]]<br />
grad_b: [1.03651294e-05 6.27722059e-06]<br />
w: [[1.08203095 1.14034734]<br />
[1.42454337 0.39919455]<br />
[1.14653011 0.84453119]], b: [-2.24515506 -1.57582409]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w: &#123;&#125;, b: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model.w.numpy(), model.b.numpy()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;loss:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cost[i]))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>w: [[1.08203095 1.14034734]<br />
[1.42454337 0.39919455]<br />
[1.14653011 0.84453119]], b: [-2.24515506 -1.57582409]<br />
loss:0.0028114152401259125</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot learning curves</span></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(no_iters), cost)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;iterations&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;mean square error&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;gd with alpha = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(lr))</span><br><span class="line">plt.savefig(<span class="string">&#x27;./figures/3.4_1.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/figures/dl_tutorial3/3.4_1.png" alt="3.4.1" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">_, pred = model(X)</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">2</span>)</span><br><span class="line">plot_targets = plt.plot(Y[:,<span class="number">0</span>], Y[:,<span class="number">1</span>], <span class="string">&#x27;b^&#x27;</span>, label=<span class="string">&#x27;targets&#x27;</span>)</span><br><span class="line">plot_pred = plt.plot(pred[:,<span class="number">0</span>], pred[:,<span class="number">1</span>], <span class="string">&#x27;ro&#x27;</span>, label=<span class="string">&#x27;predicted&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$y_1$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;$y_2$&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;gd outputs&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.savefig(<span class="string">&#x27;./figures/3.4_2.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/figures/dl_tutorial3/3.4_2.png" alt="3.4.2" /></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/examples/" rel="tag"># examples</a>
              <a href="/tags/Neuron-Layer/" rel="tag"># Neuron Layer</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/09/05/Neuron-Layer-Tutorial/" rel="prev" title="Neuron Layer Tutorial">
      <i class="fa fa-chevron-left"></i> Neuron Layer Tutorial
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/09/13/Constituency-Grammars-and-Parsing/" rel="next" title="Constituency Grammars and Parsing">
      Constituency Grammars and Parsing <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#example-1-output-of-perceptron-layer"><span class="nav-number">1.</span> <span class="nav-text"> Example 1 Output of perceptron layer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#solution"><span class="nav-number">1.0.1.</span> <span class="nav-text"> Solution</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#example-2-gd-of-a-softmax-classification"><span class="nav-number">2.</span> <span class="nav-text"> Example 2 GD of a softmax classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#solution-2"><span class="nav-number">2.0.1.</span> <span class="nav-text"> Solution</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#example-3-softmax-classification-of-iris-data"><span class="nav-number">3.</span> <span class="nav-text"> Example 3 Softmax classification of iris data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#solution-3"><span class="nav-number">3.0.1.</span> <span class="nav-text"> Solution</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#example-4-gd-of-a-perceptron-layer"><span class="nav-number">4.</span> <span class="nav-text"> Example 4 GD of a perceptron layer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#solution-4"><span class="nav-number">4.0.1.</span> <span class="nav-text"> Solution</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Run</p>
  <div class="site-description" itemprop="description">This blog will record my thinking and learning notes.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Run</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://example.com/2022/09/07/Neuron-Layer-Examples/',]
      });
      });
  </script>

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '80fcc00a44c898c469f7',
      clientSecret: 'f100b22e2b1789c00cb57522c7aae1fdc231c97a',
      repo        : 'lytinn.github.io',
      owner       : 'LYTinn',
      admin       : ['LYTinn'],
      id          : '0da85b4b57cb6645ae967cd356ee0635',
        language: 'en',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
