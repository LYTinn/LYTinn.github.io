<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Introduction SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization  Dataset Motivation Result   Unsupervised Data Augmentation fo">
<meta property="og:type" content="article">
<meta property="og:title" content="Sentiment Analysis paper read">
<meta property="og:url" content="http://example.com/2022/09/05/Sentiment-Analysis-paper-read/index.html">
<meta property="og:site_name" content="LYTinn">
<meta property="og:description" content="Introduction SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization  Dataset Motivation Result   Unsupervised Data Augmentation fo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/figures/NLP/MA-BERT.png">
<meta property="article:published_time" content="2022-09-05T06:03:13.000Z">
<meta property="article:modified_time" content="2022-09-08T02:34:18.342Z">
<meta property="article:author" content="Run">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="Sentiment Analysis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/figures/NLP/MA-BERT.png">

<link rel="canonical" href="http://example.com/2022/09/05/Sentiment-Analysis-paper-read/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Sentiment Analysis paper read | LYTinn</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="LYTinn" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">LYTinn</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">My learning notes</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/09/05/Sentiment-Analysis-paper-read/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Run">
      <meta itemprop="description" content="This blog will record my thinking and learning notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LYTinn">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Sentiment Analysis paper read
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-05 14:03:13" itemprop="dateCreated datePublished" datetime="2022-09-05T14:03:13+08:00">2022-09-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-09-08 10:34:18" itemprop="dateModified" datetime="2022-09-08T10:34:18+08:00">2022-09-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Natural-Language-Processing/" itemprop="url" rel="index"><span itemprop="name">Natural Language Processing</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#smart-robust-and-efficient-fine-tuning-for-pre-trained-natural-language-models-through-principled-regularized-optimization">SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization</a>
<ul>
<li><a href="#dataset">Dataset</a></li>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#result">Result</a></li>
</ul>
</li>
<li><a href="#unsupervised-data-augmentation-for-consistency-training">Unsupervised Data Augmentation for Consistency Training</a>
<ul>
<li><a href="#dataset-1">Dataset</a></li>
<li><a href="#motivation-1">Motivation</a></li>
<li><a href="#result-1">Result</a></li>
</ul>
</li>
<li><a href="#xlnet-generalized-autoregressive-pretraining-for-language-understanding">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a>
<ul>
<li><a href="#dataset-2">Dataset</a></li>
<li><a href="#motivation-2">Motivation</a></li>
<li><a href="#result-2">Result</a></li>
</ul>
</li>
<li><a href="#ernie-doc-a-retrospective-long-document-modeling-transformer">ERNIE-Doc: A Retrospective Long-Document Modeling Transformer</a>
<ul>
<li><a href="#dataset-3">Dataset</a></li>
<li><a href="#motivation-3">Motivation</a></li>
<li><a href="#result-3">Result</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li><a href="#ma_bert-learning-representation-by-incorporating-multi-attribute-knowledge-in-transformers">MA_BERT: Learning Representation by Incorporating Multi-Attribute Knowledge in Transformers.</a>
<ul>
<li><a href="#dataset-4">Dataset</a></li>
<li><a href="#motivation-4">Motivation</a></li>
<li><a href="#result-4">Result</a></li>
</ul>
</li>
</ul>
<h1 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h1>
<p>In this post, we will read some top papers about sentiment analysis. The papers are choosen from <a target="_blank" rel="noopener" href="https://paperswithcode.com/task/sentiment-analysis">paper with code</a>.</p>
<h1 id="smart-robust-and-efficient-fine-tuning-for-pre-trained-natural-language-models-through-principled-regularized-optimization"><a class="markdownIt-Anchor" href="#smart-robust-and-efficient-fine-tuning-for-pre-trained-natural-language-models-through-principled-regularized-optimization"></a> SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization</h1>
<p>The <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.03437v5.pdf">SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization</a> published in 2019 is the state-of-the -art for sentiment analysis on SST-2 Binary classification. It achieves 97.5% in accuracy.</p>
<h2 id="dataset"><a class="markdownIt-Anchor" href="#dataset"></a> Dataset</h2>
<p>The dataset of this paper is the <strong>Standford Sentiment Treebank (SST)</strong>. SST is a corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language. The corpus is based on the dataset introduced by Pang and Lee (2005) and consists of 11,855 single sentences extracted from <strong>movie reviews</strong>. It was parsed with the Stanford parser and includes a total of 215,154 unique phrases from those parse trees, each annotated by 3 human judges.</p>
<p>Each phrase is labelled as either <em>negative, somewhat negative, neutral, somewhat positive</em> or <em>positive</em>. The corpus with all 5 labels is referred to as SST-5 or SST fine-grained. Binary classification experiments on full sentences (<em>negative</em> or <em>somewhat negative</em> vs <em>somewhat positive</em> or <em>positive</em> with <em>neutral</em> sentences discarded) refer to the dataset as SST-2 or SST binary.</p>
<h2 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h2>
<p>When performing NLP models on downstream tasks, because of the limit fine-tuning data resources and high complexity of pre-trained model, the fine-tuning always cause overfitting.</p>
<p>The team comes up with a framework to fine-tune the pre-trained model on the downstream tasks, avoiding over-fitting and getting a better performance.</p>
<h2 id="result"><a class="markdownIt-Anchor" href="#result"></a> Result</h2>
<p>Achieves a new state-of-the-art performance on many NLP benchmarks like GLUE, SNLI, SciTail, ANLI.</p>
<h1 id="unsupervised-data-augmentation-for-consistency-training"><a class="markdownIt-Anchor" href="#unsupervised-data-augmentation-for-consistency-training"></a> Unsupervised Data Augmentation for Consistency Training</h1>
<p>The <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.12848v6.pdf">Unsupervised Data Augmentation for Consistency Training</a> published on 2019 is the state-of-the-art for sentiment analysis on Amazon Review Full. It achieves 65.83% accuracy on Amazon Review dataset.</p>
<h2 id="dataset-2"><a class="markdownIt-Anchor" href="#dataset-2"></a> Dataset</h2>
<p>This dataset contains product reviews and metadata from Amazon, including 233.1 million reviews spanning May 1996 - Oct 2018.</p>
<p>This dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), links (also viewed/also bought graphs), and transaction metadata for each review shown on the review page.</p>
<h2 id="motivation-2"><a class="markdownIt-Anchor" href="#motivation-2"></a> Motivation</h2>
<p>Substituting simple moising operations with davanced data augmentation methods, improves the performance on consistency training framework.</p>
<p><strong>Consistency training</strong> is used to enforce the predictions to be similar for an unlabeled example and the augmented unlabeled example</p>
<h2 id="result-2"><a class="markdownIt-Anchor" href="#result-2"></a> Result</h2>
<p>Finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.</p>
<h1 id="xlnet-generalized-autoregressive-pretraining-for-language-understanding"><a class="markdownIt-Anchor" href="#xlnet-generalized-autoregressive-pretraining-for-language-understanding"></a> XLNet: Generalized Autoregressive Pretraining for Language Understanding</h1>
<p>The <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.08237v2.pdf">XLNet</a> is state-of-the-art model for Sentiment Analysis on IMDb.</p>
<h2 id="dataset-3"><a class="markdownIt-Anchor" href="#dataset-3"></a> Dataset</h2>
<p>The <strong>IMDb Movie Reviews</strong> dataset is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative. The dataset contains an even number of positive and negative reviews. Only highly polarizing reviews are considered. A negative review has a score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">\leq 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> out of 10, and a positive review has a score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">\geq 7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span> out of 10. No more than 30 reviews are included per movie. The dataset contains additional unlabeled data.</p>
<h2 id="motivation-3"><a class="markdownIt-Anchor" href="#motivation-3"></a> Motivation</h2>
<p>To overcome the defects of autoencoding model (like BERT).</p>
<p>XLNet using autoregressive pretraining method that</p>
<ul>
<li>enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order</li>
<li>overcomes the limitations of BERT which neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy.</li>
</ul>
<h2 id="result-3"><a class="markdownIt-Anchor" href="#result-3"></a> Result</h2>
<p>Outperforms BERT on 20 tasks.</p>
<h1 id="ernie-doc-a-retrospective-long-document-modeling-transformer"><a class="markdownIt-Anchor" href="#ernie-doc-a-retrospective-long-document-modeling-transformer"></a> ERNIE-Doc: A Retrospective Long-Document Modeling Transformer</h1>
<p>The <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2012.15688.pdf">ERNIE-Doc</a> is an improvement to transformer architecture.</p>
<h2 id="dataset-4"><a class="markdownIt-Anchor" href="#dataset-4"></a> Dataset</h2>
<p>The <strong>IMDb Movie Reviews</strong> dataset is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative. The dataset contains an even number of positive and negative reviews. Only highly polarizing reviews are considered. A negative review has a score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">\leq 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> out of 10, and a positive review has a score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">\geq 7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span> out of 10. No more than 30 reviews are included per movie. The dataset contains additional unlabeled data.</p>
<h2 id="motivation-4"><a class="markdownIt-Anchor" href="#motivation-4"></a> Motivation</h2>
<p>Uing recurrence transformer to overcome the defect of transformer on long text.</p>
<h2 id="result-4"><a class="markdownIt-Anchor" href="#result-4"></a> Result</h2>
<p>Improved the state-of-th-art language modeling result of perplexity to 16.8 on WikiText-103. It also outperformed competitive pretraining models by a large margin on most language understanding tasks, such as text classification and question answering.</p>
<h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2>
<p>Suitable to be innovations.</p>
<h1 id="ma_bert-learning-representation-by-incorporating-multi-attribute-knowledge-in-transformers"><a class="markdownIt-Anchor" href="#ma_bert-learning-representation-by-incorporating-multi-attribute-knowledge-in-transformers"></a> MA_BERT: Learning Representation by Incorporating Multi-Attribute Knowledge in Transformers.</h1>
<p>The <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.findings-acl.206.pdf">MA-BERT</a> is state-of-the-art model for Sentiment Analysis on User and product information</p>
<h2 id="dataset-5"><a class="markdownIt-Anchor" href="#dataset-5"></a> Dataset</h2>
<p>The <strong>IMDb Movie Reviews</strong> dataset is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative. The dataset contains an even number of positive and negative reviews. Only highly polarizing reviews are considered. A negative review has a score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">\leq 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> out of 10, and a positive review has a score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">\geq 7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span> out of 10. No more than 30 reviews are included per movie. The dataset contains additional unlabeled data.</p>
<h2 id="motivation-5"><a class="markdownIt-Anchor" href="#motivation-5"></a> Motivation</h2>
<p>Incorporating attribute information from text.<br />
<img src="/figures/NLP/MA-BERT.png" alt="MA-BERT" /></p>
<h2 id="result-5"><a class="markdownIt-Anchor" href="#result-5"></a> Result</h2>
<p>Outperformed pre-trained BERT models and other methods incorporating external attribute knowledge.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/NLP/" rel="tag"># NLP</a>
              <a href="/tags/Sentiment-Analysis/" rel="tag"># Sentiment Analysis</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/09/05/Parts-of-Speech-and-Named-Entities/" rel="prev" title="Parts of Speech and Named Entities">
      <i class="fa fa-chevron-left"></i> Parts of Speech and Named Entities
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/09/05/Neuron-Layer-Tutorial/" rel="next" title="Neuron Layer Tutorial">
      Neuron Layer Tutorial <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#introduction"><span class="nav-number">1.</span> <span class="nav-text"> Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#smart-robust-and-efficient-fine-tuning-for-pre-trained-natural-language-models-through-principled-regularized-optimization"><span class="nav-number">2.</span> <span class="nav-text"> SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dataset"><span class="nav-number">2.1.</span> <span class="nav-text"> Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#motivation"><span class="nav-number">2.2.</span> <span class="nav-text"> Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#result"><span class="nav-number">2.3.</span> <span class="nav-text"> Result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#unsupervised-data-augmentation-for-consistency-training"><span class="nav-number">3.</span> <span class="nav-text"> Unsupervised Data Augmentation for Consistency Training</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dataset-2"><span class="nav-number">3.1.</span> <span class="nav-text"> Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#motivation-2"><span class="nav-number">3.2.</span> <span class="nav-text"> Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#result-2"><span class="nav-number">3.3.</span> <span class="nav-text"> Result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#xlnet-generalized-autoregressive-pretraining-for-language-understanding"><span class="nav-number">4.</span> <span class="nav-text"> XLNet: Generalized Autoregressive Pretraining for Language Understanding</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dataset-3"><span class="nav-number">4.1.</span> <span class="nav-text"> Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#motivation-3"><span class="nav-number">4.2.</span> <span class="nav-text"> Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#result-3"><span class="nav-number">4.3.</span> <span class="nav-text"> Result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ernie-doc-a-retrospective-long-document-modeling-transformer"><span class="nav-number">5.</span> <span class="nav-text"> ERNIE-Doc: A Retrospective Long-Document Modeling Transformer</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dataset-4"><span class="nav-number">5.1.</span> <span class="nav-text"> Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#motivation-4"><span class="nav-number">5.2.</span> <span class="nav-text"> Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#result-4"><span class="nav-number">5.3.</span> <span class="nav-text"> Result</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conclusion"><span class="nav-number">5.4.</span> <span class="nav-text"> Conclusion</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ma_bert-learning-representation-by-incorporating-multi-attribute-knowledge-in-transformers"><span class="nav-number">6.</span> <span class="nav-text"> MA_BERT: Learning Representation by Incorporating Multi-Attribute Knowledge in Transformers.</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dataset-5"><span class="nav-number">6.1.</span> <span class="nav-text"> Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#motivation-5"><span class="nav-number">6.2.</span> <span class="nav-text"> Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#result-5"><span class="nav-number">6.3.</span> <span class="nav-text"> Result</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Run</p>
  <div class="site-description" itemprop="description">This blog will record my thinking and learning notes.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Run</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://example.com/2022/09/05/Sentiment-Analysis-paper-read/',]
      });
      });
  </script>

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '80fcc00a44c898c469f7',
      clientSecret: 'f100b22e2b1789c00cb57522c7aae1fdc231c97a',
      repo        : 'lytinn.github.io',
      owner       : 'LYTinn',
      admin       : ['LYTinn'],
      id          : 'e84aa82e25bfcc3ed38c2cdb5724638a',
        language: 'en',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
